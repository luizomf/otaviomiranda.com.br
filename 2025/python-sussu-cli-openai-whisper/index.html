<!doctype html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>
      Transcreva √°udio com Python: Sussu CLI + OpenAI Whisper - Ot√°vio Miranda
    </title>
    <meta
      name="description"
      content="Aprenda a usar o Sussu, uma ferramenta de linha de comando feita em Python que utiliza o modelo Whisper da OpenAI para transcrever √°udios e v√≠deos de forma simples e eficiente."
    />

    <link rel="stylesheet" href="../../css/markdown.css" />

    <link rel="icon" type="image/webp" href="../../imgs/favicon-1.webp" />

    <!-- Estilo escuro para markdown (GitHub dark) -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.8.1/github-markdown-dark.min.css"
    />

    <!-- Tema dark do highlight.js -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github-dark.min.css"
    />
  </head>
  <body>
    <nav class="breadcrumb-nav">
      <a href="/">&larr; ir para in√≠cio</a>

      <form
        id="main-search"
        action="https://www.google.com/search"
        method="get"
        target="_blank"
      >
        <input type="search" name="q" placeholder="Buscar no site via Google" />
        <button type="submit">Buscar</button>
      </form>
    </nav>

    <article class="markdown-body" id="content"></article>

    <!-- prettier-ignore -->
    <script type="text/markdown" id="markdown-source">





# sussu(rro): CLI educacional com OpenAI Whisper

> Ferramenta de linha de comando focada em educa√ß√£o e IA offline. Utiliza o
> poder do Whisper da OpenAI para transcrever √°udios e v√≠deos de forma simples e
> eficiente.

Esses s√£o todos os links que menciono nos dois v√≠deos:

- [(üö´ FAILED) whisper em tempo real via microfone](https://www.otaviomiranda.com.br/2025/whisper-live-sera-que-deu-certo/)
- [logging ‚Äî Logging facility for Python](https://docs.python.org/3/library/logging.html)
- [sussu(rro): CLI educacional com OpenAI Whisper](https://www.otaviomiranda.com.br/2025/python-sussu-cli-openai-whisper/)
- [openai / whisper](https://github.com/openai/whisper)

### üé• Parte 1 ‚Äî CLI do Whisper:

- [Whisper OpenAI: Guia Completo de Transcri√ß√£o com Intelig√™ncia Artificial (v√≠deo e √°udio)](https://youtu.be/y15070biffg)

### üíª Parte 2 ‚Äî C√≥digo do `sussu` com Python + Whisper:

- [Whisper com Python: transcri√ß√£o de √°udio com Intelig√™ncia Artificial no seu projeto](https://youtu.be/SAt7yuO8DX4)

---

## Sobre o Whisper e a OpenAI

Estava curioso para saber se a OpenAI usa o Whisper em seus pr√≥prios produtos,
ent√£o questionei o ChatGPT...

> **Eu:** A OpenAI usa o Whisper internamente em algum recurso que as pessoas
> consomem? \
> **ChatGPT:** Sim, a OpenAI usa o Whisper como base para recursos de
> transcri√ß√£o e compreens√£o de √°udio em produtos como o ChatGPT com entrada de
> voz. Ele tamb√©m √© utilizado em APIs que envolvem reconhecimento de fala, como
> a `speech-to-text` da OpenAI.

---

## Sobre este documento:

Estou tentando manter este documento (`README.md`) sincronizado com o link
abaixo. Caso n√£o encontre o que procura aqui, acesse:

- [Transcreva √°udio com Python: Sussu CLI + OpenAI Whisper](https://www.otaviomiranda.com.br/2025/python-sussu-cli-openai-whisper/)

---

## Introdu√ß√£o geral

Ao rodar este projeto, uma das primeiras coisas que voc√™ vai querer fazer √© usar
o comando `whisper` para fazer a transcri√ß√£o inicial de algum v√≠deo ou √°udio.
Essa transcri√ß√£o √© um √≥timo jeito de ver na pr√°tica como o **Whisper** trabalha
e o que esperar dos resultados.

- [Reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper)
- [Reposit√≥rio do `sussu`](https://github.com/luizomf/sussu)

Vamos come√ßar pela **instala√ß√£o** do projeto, isso j√° coloca os comandos `sussu`
e `whisper` funcionando direto no seu terminal.

---

## Instala√ß√£o do `sussu`

Se voc√™ encontrar alguma dificuldade com o ambiente, recomendo meu tutorial
completo:

- [Ambiente Python Moderno 2025: UV, Ruff, Pyright, pyproject.toml e VS Code](https://www.youtube.com/watch?v=HuAc85cLRx0)

Este projeto utiliza o **Python 3.11.9** por quest√µes de compatibilidade com o
**Whisper**. Evite alterar essa vers√£o se n√£o souber o que est√° fazendo, pois
**eu j√° testei tudo para voc√™**.

Al√©m disso, este projeto usa o [`uv`](https://docs.astral.sh/uv/) para o
gerenciamento geral (pacotes, vers√£o do Python, etc.).

Para instalar tudo, basta rodar o comando:

```sh
# Se ainda n√£o clonou o reposit√≥rio
git clone https://github.com/luizomf/sussu.git
# Acesse a pasta do projeto
cd sussu
# Sincronizando
uv sync
# √© s√≥ isso mesmo üòÖ
```

`uv sync` √© suficiente para:

- Baixar e instalar o `python 3.11.9`
- Criar o ambiente virtual em `.venv`
- Instalar os pacotes necess√°rios
- Buildar o `whisper` e o `sussu`

---

## `ffmpeg`

Voc√™ tamb√©m precisar√° ter o **`ffmpeg`** instalado. Ele √© um software de c√≥digo
aberto com v√°rias ferramentas e bibliotecas para trabalhar com arquivos
multim√≠dia, especialmente √°udio e v√≠deo. Embora o `whisper` foque na transcri√ß√£o
de √°udio, o `ffmpeg` √© quem permite que voc√™ transcreva seus v√≠deos diretamente,
sem precisar convert√™-los para √°udio antes.

Para instalar o `ffmpeg` no seu sistema, voc√™ pode usar um dos comandos abaixo.
Eles foram retirados diretamente do
[reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper):

```bash
# No Ubuntu ou Debian
sudo apt update && sudo apt install ffmpeg

# No Arch Linux
sudo pacman -S ffmpeg

# No macOS com Homebrew (https://brew.sh/)
brew install ffmpeg

# No Windows com Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# No Windows usando Scoop (https://scoop.sh/)
scoop install ffmpeg

# Adicional: No Windows usando winget (https://winstall.app/apps/Gyan.FFmpeg)
winget install --id=Gyan.FFmpeg -e
```

**Observa√ß√£o:** Dos comandos listados, os √∫nicos que testei e aprovei (‚úÖ) foram
os para **macOS** e **Ubuntu**.

---

## Rodando pela Primeira Vez

Para verificar se tudo foi instalado corretamente, voc√™ tem duas op√ß√µes:
**ativar o ambiente virtual** ou usar o comando **`uv run`**. Sugiro que voc√™
teste com `whisper -h`. Esse comando deve exibir a ajuda completa do `whisper`,
indicando que ele est√° funcionando. Veja os exemplos:

```bash
uv run whisper -h
# Ou, se voc√™ j√° ativou o ambiente virtual
whisper -h
```

**Observa√ß√£o:** Editores de c√≥digo como **VS Code** ou **Zed** podem ativar o
ambiente virtual automaticamente ao abrir um novo terminal, desde que estejam
configurados corretamente. Se for o seu caso, basta fechar e abrir o terminal
novamente para que as mudan√ßas fa√ßam efeito.

---

## `whisper -h`: Entendendo Alguns Argumentos Importantes

Ao digitar `whisper -h` ou `whisper --help`, voc√™ pode se surpreender com a
quantidade de argumentos dispon√≠veis. Mas n√£o se preocupe! Voc√™ n√£o precisa
saber o que cada um deles faz. Na verdade, a maioria dos argumentos j√° vem com
valores padr√£o que funcionam perfeitamente. No entanto, se voc√™ quiser
personalizar um pouco o comportamento da ferramenta, vamos analisar alguns dos
mais importantes.

O `whisper` utiliza a biblioteca `argparse` do Python para gerar essa
documenta√ß√£o de ajuda (`help`) completa e bem organizada. Se voc√™ tiver
interesse em aprender mais sobre como criar interfaces de linha de comando
profissionais com Python, confira meu v√≠deo:

- [Python e argparse: Do Zero a uma CLI Profissional (Projeto Real na Pr√°tica)](https://www.youtube.com/watch?v=Ad6934NXn4A)

---

### Argumentos Essenciais do `whisper`

Vamos come√ßar com os argumentos que voc√™ usar√° com mais frequ√™ncia:

**`audio`**: Este √© o **argumento posicional** principal. Ele representa o
caminho completo (localiza√ß√£o) do arquivo de √°udio ou v√≠deo que voc√™ quer
transcrever.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4
```

No exemplo acima, voc√™ notou que especificamos apenas o caminho do arquivo de
v√≠deo. Nas pr√≥ximas se√ß√µes, vou detalhar as op√ß√µes que mais utilizo para
personalizar a transcri√ß√£o.

---

**`--model MODEL`**: Este argumento serve para **definir qual modelo ser√° usado
na transcri√ß√£o** do seu √°udio ou v√≠deo. Ele √© opcional, e o valor padr√£o √©
`turbo`. O modelo `turbo` √© excelente: r√°pido e multil√≠ngue, mas requer cerca de
**6GB de VRAM** para rodar.

Talvez voc√™ queira usar outros modelos que exigem mais ou menos recursos do seu
hardware, ou que possuem mais ou menos par√¢metros (como `base`, `small`,
`medium`, etc.).

Aqui est√£o os modelos dispon√≠veis e seus requisitos aproximados de VRAM:

- **`tiny`**: 39M par√¢metros, `tiny.en` e `tiny`, VRAM ~1 GB
- **`base`**: 74M par√¢metros, `base.en` e `base`, VRAM ~1 GB
- **`small`**: 244M par√¢metros, `small.en` e `small`, VRAM ~2 GB
- **`medium`**: 769M par√¢metros, `medium.en` e `medium`, VRAM ~5 GB
- **`large`**: 1550M par√¢metros, `large`, `large-v2` e `large-v3`, VRAM ~10 GB
- **`turbo`**: 809M par√¢metros, `turbo`, VRAM ~6 GB

**VRAM** √© um tipo de mem√≥ria RAM especializada que as placas de v√≠deo (GPUs)
usam. Mas n√£o se preocupe se voc√™ n√£o tiver uma placa de v√≠deo dedicada! Se seu
computador compartilha a RAM com a GPU, o que acontece em Macs com chips Apple
Silicon (M1, M2, M3 e posteriores), por exemplo, voc√™ conseguir√° usar os modelos
do Whisper normalmente.

Nesses casos, o que realmente limita √© a **quantidade total de mem√≥ria RAM
dispon√≠vel no seu sistema**. Por exemplo: se voc√™ tem apenas 8GB de RAM, o ideal
√© testar os modelos `tiny`, `base` ou `small`.

A partir do modelo `medium`, √© bem prov√°vel que voc√™ perceba uma **queda
dr√°stica no desempenho geral da sua m√°quina**, j√° que a mem√≥ria ser√°
completamente consumida.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2
```

---

**`--device DEVICE`**: Este argumento √© para voc√™ que possui uma **placa de
v√≠deo NVIDIA com drivers CUDA** e uma vers√£o compat√≠vel com o PyTorch. Se for o
seu caso, vale a pena usar `--device cuda` para aproveitar o processamento da
GPU. Caso contr√°rio, n√£o se preocupe em alterar esta op√ß√£o, o padr√£o √© `cpu`
(processamento pela CPU) e funcionar√° perfeitamente.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2 --device cpu
```

---

**`--output_dir` ou `-o`**: Define o **caminho da pasta onde as transcri√ß√µes
ser√£o salvas**. Por padr√£o, os arquivos ser√£o salvos na raiz do projeto (`.`).

---

**`--output_format` ou `-f`**: Permite que voc√™ escolha o **formato da
transcri√ß√£o ou legenda** gerada. As op√ß√µes dispon√≠veis s√£o: `txt`, `vtt`, `srt`,
`tsv`, `json` e `all` (que gera todos os formatos). O padr√£o √© `all`.

---

**Exemplo:**

O arquivo de sa√≠da ser√° `srt` (SubRip) na pasta indicada em `-o`. Essa pasta
ser√° criada caso n√£o exista.

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo -o caminho/da/pasta_de_saida -f srt
```

---

**`--task`**: Com este argumento, voc√™ pode escolher entre **transcrever o
√°udio** no idioma original ou **traduzir para o ingl√™s**. As op√ß√µes s√£o
`transcribe` (o padr√£o, que transcreve no idioma falado no √°udio) ou `translate`
(que traduz o conte√∫do para o ingl√™s).

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo --task transcribe
```

---

**`--language`**: Este argumento permite que voc√™ **especifique o idioma falado
no √°udio ou v√≠deo**. Existem muitas op√ß√µes de idiomas dispon√≠veis. Se voc√™ n√£o
informar esse argumento, o `whisper` √© inteligente o suficiente para detectar
automaticamente o idioma do conte√∫do.

---

Forma curta (language code):

```python
["af", "am", "ar", "as", "az", "ba", "be", "bg", "bn", "bo", "br", "bs", "ca",
"cs", "cy", "da", "de", "el", "en", "es", "et", "eu", "fa", "fi", "fo", "fr",
"gl", "gu", "ha", "haw", "he", "hi", "hr", "ht", "hu", "hy", "id", "is", "it",
"ja", "jw", "ka", "kk", "km", "kn", "ko", "la", "lb", "ln", "lo", "lt", "lv",
"mg", "mi", "mk", "ml", "mn", "mr", "ms", "mt", "my", "ne", "nl", "nn", "no",
"oc", "pa", "pl", "ps", "pt", "ro", "ru", "sa", "sd", "si", "sk", "sl", "sn",
"so", "sq", "sr", "su", "sv", "sw", "ta", "te", "tg", "th", "tk", "tl", "tr",
"tt", "uk", "ur", "uz", "vi", "yi", "yo", "yue", "", "zh"]
```

- Exemplo para portugu√™s do Brasil: `--language pt`

---

Forma longa (language name):

```python
["Afrikaans", "Albanian", "Amharic", "Arabic", "Armenian", "Assamese",
"Azerbaijani", "Bashkir", "Basque", "Belarusian", "Bengali", "Bosnian",
"Breton", "Bulgarian", "Burmese", "Cantonese", "Castilian", "Catalan",
"Chinese", "Croatian", "Czech", "Danish", "Dutch", "English", "Estonian",
"Faroese", "Finnish", "Flemish", "French", "Galician", "Georgian", "German",
"Greek", "Gujarati", "Haitian", "Haitian Creole", "Hausa", "Hawaiian", "Hebrew",
"Hindi", "Hungarian", "Icelandic", "Indonesian", "Italian", "Japanese",
"Javanese", "Kannada", "Kazakh", "Khmer", "Korean", "Lao", "Latin", "Latvian",
"Letzeburgesch", "Lingala", "Lithuanian", "Luxembourgish", "Macedonian",
"Malagasy", "Malay", "Malayalam", "Maltese", "Mandarin", "Maori", "Marathi",
"Moldavian", "Moldovan", "Mongolian", "Myanmar", "Nepali", "Norwegian",
"Nynorsk", "Occitan", "Panjabi", "Pashto", "Persian", "Polish", "Portuguese",
"Punjabi", "Pushto", "Romanian", "Russian", "Sanskrit", "Serbian", "Shona",
"Sindhi", "Sinhala", "Sinhalese", "Slovak", "Slovenian", "Somali", "Spanish",
"Sundanese", "Swahili", "Swedish", "Tagalog", "Tajik", "Tamil", "Tatar",
"Telugu", "Thai", "Tibetan", "Turkish","Turkmen", "Ukrainian", "Urdu", "Uzbek",
"Valencian", "Vietnamese", "Welsh", "Yiddish", "Yoruba"]
```

- Exemplo para portugu√™s do Brasil: `--language Portuguese`

Se precisar de um dicion√°rio completo com todos os idiomas e seus c√≥digos, ele
est√° dispon√≠vel em `whisper.tokenizer.LANGUAGES` dentro do c√≥digo do `whisper`.

**Exemplo:**

```bash
# Para o comando ficar menor, vou manter tudo padr√£o
# model turbo (padr√£o)
# task transcribe (padr√£o)
# etc...
# Idioma falado no v√≠deo "Portugu√™s"
whisper /caminho/do/seu/arquivo.mp4 --language pt
```

---

**`--temperature`:** controla a "criatividade" do modelo. Vai de `0.0` a `1.0`.
Quanto mais alto, mais liberdade o modelo tem pra decidir os pr√≥ximos tokens.
Esse par√¢metro interage com `--beam_size`, `--patience` e `--best_of`.

---

**`--beam_size`:** n√∫mero de hip√≥teses que o modelo mant√©m em paralelo. Pensa
como se ele testasse v√°rios caminhos ao mesmo tempo e no fim escolhesse o
melhor. O padr√£o √© `5` e **s√≥ funciona se `--temperature == 0.0`**.

---

**`--patience`:** fator de toler√¢ncia que faz o modelo continuar explorando
novas hip√≥teses mesmo depois de achar uma aceit√°vel. Requer
`--temperature == 0.0` e `--beam_size > 1`.

---

**`--best_of`:** n√∫mero de amostras diferentes geradas antes de escolher a
melhor. Funciona apenas quando `--temperature > 0.0`.

---

**Cola r√°pida:**

```
- temperature > 0 ‚Üí usa sampling
  ‚úÖ --best_of 5 (5 amostras)
  üî¥ --beam_size (ignorado)
  üî¥ --patience (ignorado)

- temperature == 0 ‚Üí usa beam search
  ‚úÖ --beam_size 5 (5 hip√≥teses)
  ‚úÖ --patience 2 (2 x 5 = 10 hip√≥teses)
  üî¥ --best_of (ignorado)

- temperature == 0 ‚Üí greedy
  ‚úÖ --beam_size 1 (1 hip√≥tese)
  üî¥ --patience (n√£o faz diferen√ßa)
  üî¥ --best_of (ignorado)
```

**Importante:** Quanto maiores os valores de `--beam_size`, `--patience` e
`--best_of`, mais lento e "indeciso" o modelo tende a ficar. Isso acontece
porque ele precisa gerar mais hip√≥teses ou amostras e, em seguida, tomar uma
decis√£o entre elas. Fa√ßa testes r√°pidos para confirmar esse comportamento.

**Observa√ß√£o sincera:**

Na pr√°tica, o modelo vai responder como foi treinado, independente do seu
capricho nas configs. Trocar `temperature`, `beam_size`, `patience` e afins pode
virar desperd√≠cio de tempo.

**Recomenda√ß√£o direta:** s√≥ mexa nessas op√ß√µes se:

- o modelo come√ßar a repetir palavras (loop)
- estiver errando demais em blocos grandes

Se for s√≥ por causa de uma ou duas palavras... aceita e segue. Ou ent√£o faz
igual eu: **testa tudo por uma semana e conclui que o padr√£o j√° era bom** üòÖ

**Exemplo:**

O arquivo de sa√≠da ser√° `srt` (SubRip) na pasta indicada em `-o`. Essa pasta
ser√° criada caso n√£o exista.

```bash
# Greedy: Mais r√°pido, mas pode errar mais por considerar apenas uma hip√≥tese por vez.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 1

# Beam Search: Utiliza 3 hip√≥teses em paralelo.
# O 'patience' padr√£o √© 1.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 3

# Sampling: Gera 5 amostras diferentes para escolher a melhor.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.7 --best_of 5
```

---

**`--temperature_increment_on_fallback`**: Este argumento permite que voc√™
**aumente a temperatura do modelo em casos de falha na transcri√ß√£o**. Se o
modelo encontrar dificuldades na temperatura `0.0`, ele far√° um "fallback" e
tentar√° com a temperatura incrementada. O valor tamb√©m varia de `0.0` a `1.0`.
No entanto, **cuidado: definir `0.0` para este argumento causar√° um erro
`ZeroDivisionError: float division by zero`** (isso pode ser um pequeno
"bugzinho" ü´£, mas, de fato, n√£o faria muito sentido usar zero aqui, j√° que o
objetivo √© justamente _incrementar_ a temperatura). O valor padr√£o √© `0.2`.

---

**`--max_line_width`**: Define a **quantidade m√°xima de caracteres por linha**
na sua legenda. O valor padr√£o √© `1000` (um limite bastante alto, codificado
diretamente na classe `SubtitlesWriter` do `whisper`). Eu, particularmente,
costumo usar `45` para uma melhor legibilidade. **Importante:** Se este
argumento for utilizado, ele anula o `--max_words_per_line`. **Requer
`--word_timestamps True`**.

---

**`--max_line_count`**: Controla a **quantidade m√°xima de linhas por legenda**
(ou "bloco" de texto). Eu uso o valor `2`, mas, nos meus testes, percebi que
isso for√ßa todas as legendas a terem sempre duas linhas. Para mim, n√£o √© um
problema, mas vale a pena voc√™ testar para ver como se adapta ao seu caso.
**Requer `--word_timestamps True`**.

---

**`--max_words_per_line`**: Determina a **quantidade m√°xima de palavras por
linha** na legenda. O padr√£o tamb√©m √© um valor alto, `1000` (tamb√©m "hardcoded"
na classe `SubtitlesWriter`). Embora eu n√£o costume us√°-lo, acredito que `5`
palavras por linha pode resultar em uma leitura mais confort√°vel. **Aten√ß√£o:**
Ser√° anulado por `--max_line_width` caso voc√™ use ambos no mesmo comando.
**Requer `--word_timestamps True`**.

---

**`--highlight_words`**: Este √© o argumento respons√°vel por criar o **efeito de
"karaok√™"** na sua transcri√ß√£o. Ele faz com que cada palavra falada seja
sublinhada no momento exato em que √© pronunciada. **Requer
`--word_timestamps True`**.

---

**`--word_timestamps`**: Este argumento √© a **chave** para ativar os recursos de
sincroniza√ß√£o detalhada. Ao defini-lo como `True`, o modelo passar√° a gerar
**timestamps para cada palavra**, em vez de apenas por blocos de frase. Isso
pode, sim, aumentar consideravelmente o tempo de transcri√ß√£o, mas √© um requisito
fundamental para que v√°rios outros argumentos (como os de formata√ß√£o de linha e
destaque de palavras) funcionem. O valor padr√£o √© `False`.

---

**Exemplo Completo de Transcri√ß√£o Detalhada**

Veja um exemplo de como combinar v√°rios desses argumentos para obter uma
transcri√ß√£o formatada e com destaque de palavras:

```bash
# A '\' (barra invertida no final da linha) √© usada apenas para indicar que
# o comando continua na linha de baixo. Isso √© uma boa pr√°tica para evitar
# que o comando fique muito longo na horizontal e melhora a legibilidade.
whisper meu_video.mp4 \
  --model large-v2 \
  --language pt \
  --output_format srt \
  --word_timestamps True \
  --highlight_words True \
  --max_line_width 45 \
  --max_line_count 2
```

---

**`--initial_prompt`**:

Este √© um texto opcional que serve como um **"empurr√£ozinho" para o modelo antes
que ele comece a transcrever**. Funciona como uma dica de estilo ou contexto. No
entanto, √© importante notar que ele s√≥ influencia a **primeira "janela" do
√°udio** (que por padr√£o tem 30 segundos).

**Exemplo Pr√°tico:**

Se o seu v√≠deo √© sobre programa√ß√£o, especificamente Python, voc√™ pode passar um
prompt como este:

```bash
--initial_prompt "v√≠deo de uma explica√ß√£o sobre programa√ß√£o com destaque para bibliotecas do Python"
```

Isso pode ajudar o modelo a reconhecer e transcrever termos t√©cnicos de
programa√ß√£o e Python com mais precis√£o. Mas, como dito, n√£o espere milagres para
o v√≠deo inteiro; essa influ√™ncia √© apenas um toque inicial. Para as janelas
seguintes, o modelo pode usar o texto transcrito anteriormente, se a op√ß√£o
`--condition_on_previous_text` estiver como `True` (que √© o padr√£o).

**Analogia para Entender Melhor:**

> Imagine que √© como dizer para um cantor, antes de ele subir no palco: \
> "Tem 300 mil pessoas te esperando, detona l√°!" \
> Ele vai subir j√° no clima certo, mas o resto da performance depender√° do show
> em si. \
> Da mesma forma, o modelo continua a transcri√ß√£o com base no que "ouviu" e
> transcreveu depois do prompt inicial.

**Cuidados com o `--initial_prompt`**:

O `--initial_prompt` pode afetar significativamente a forma como o modelo do
`whisper` opera. Em alguns casos, ele pode levar √† gera√ß√£o de legendas
excessivamente longas ou at√© mesmo fazer o modelo entrar em **loops de
repeti√ß√£o**.

**Recomenda√ß√£o:** Antes de aplicar um prompt em um v√≠deo completo, fa√ßa **testes
r√°pidos em um trecho menor** do seu v√≠deo para observar o resultado. Isso evita
surpresas e economiza tempo de processamento.

Para cortar facilmente um peda√ßo do seu v√≠deo para testes, voc√™ pode usar o
`ffmpeg` com o seguinte comando:

```bash
# Com ffmpeg
ffmpeg -i entrada.mp4 -c:v copy -c:a copy -ss 00:05:00.000 -to 00:10:00.000 saida.mp4

# Tamb√©m d√° pra usar --clip_timestamps start, end, start, end... (em segundos)
# O argumento --clip_timestamps √© detalhado mais abaixo nesse texto
# No comando abaixo ele transcreve de 1min at√© 2min (nada mais)
whisper meu_video.mp4 --clip_timestamps 60,120
```

**Entendendo o Comando `ffmpeg`:**

- `-i entrada.mp4`: Define o arquivo de v√≠deo de entrada (o seu v√≠deo original).
- `-c:v copy`: Copia o codec de v√≠deo do arquivo original, sem recodificar. Isso
  torna o processo muito mais r√°pido!
- `-c:a copy`: Copia o codec de √°udio do arquivo original, tamb√©m sem
  recodificar.
- `-ss 00:05:00.000`: Especifica o ponto de in√≠cio do corte (neste exemplo, 5
  minutos e 0 segundos do v√≠deo original).
- `-to 00:10:00.000`: Define o ponto final do corte (neste exemplo, 10 minutos e
  0 segundos do v√≠deo original).

Este comando ir√° gerar um novo arquivo de v√≠deo (`saida.mp4`) contendo apenas o
segmento entre 00:05:00 e 00:10:00 do v√≠deo original. Essa t√©cnica √©
extremamente √∫til, especialmente para v√≠deos mais longos (como os meus de 30+
minutos), pois permite testar configura√ß√µes espec√≠ficas em um peda√ßo pequeno sem
ter que processar o v√≠deo inteiro.

---

**`--condition_on_previous_text`**:

Este argumento crucial define se **o texto que j√° foi transcrito ser√° usado como
contexto** para ajudar a transcrever a pr√≥xima "janela" do √°udio.

- `True` (padr√£o): √â a configura√ß√£o ideal para a maioria dos casos. Ela ajuda a
  manter a **fluidez e a consist√™ncia** do texto, garantindo uma boa coes√£o
  entre os blocos da transcri√ß√£o.
- `False`: Desativa o uso do contexto anterior. Isso pode ser √∫til para **evitar
  "loops de erro"**, onde o modelo fica repetindo frases ou palavras
  indefinidamente.

> _Exemplo de Uso:_ \
> Se a transcri√ß√£o come√ßar a errar e ficar repetindo, por exemplo,
> `"Ol√°, pessoal, hoje vamos falar sobre..."` em loop, desativar este argumento
> (`--condition_on_previous_text=False`) pode quebrar esse ciclo vicioso.

---

**Recomenda√ß√µes Gerais para Contexto**

Para otimizar suas transcri√ß√µes, considere as seguintes dicas:

- Para v√≠deos **bem gravados**, com **√°udio limpo** e **sem erros ou repeti√ß√µes
  evidentes**, mantenha o padr√£o: `--condition_on_previous_text=True`.
- Se o modelo come√ßar a **repetir frases ou palavras** de forma indesejada,
  experimente mudar para `--condition_on_previous_text=False`.
- O `--initial_prompt` pode ajudar **somente no in√≠cio** da transcri√ß√£o. N√£o
  espere que ele resolva problemas de consist√™ncia para o v√≠deo inteiro, mas
  pode ser √∫til para guiar o modelo em termos espec√≠ficos.

---

### Par√¢metros que n√£o usei (ou quase n√£o usei ü´£):

Esses par√¢metros a√≠ de baixo **eu n√£o testei quase nada** (apenas alguns). S√≥ li
a documenta√ß√£o, pesquei uma ideia geral e traduzi pra voc√™ n√£o precisar sofrer.
Se quiser fu√ßar, fuce, mas vai por sua conta e risco. Pode ser que melhore algo,
pode ser que n√£o mude nada. Vai depender do √°udio, da fase da lua e do humor do
modelo üòÖ.

Se eu come√ßar a usar alguma dessas op√ß√µes nas minhas transcri√ß√µes, prometo que
volto aqui e atualizo esse trecho. Alguns deles eu cheguei a testar de forma
supercifical (explico nos argumentos).

---

**`--length_penalty`**

Controla a penaliza√ß√£o para _sequ√™ncias longas_. Valor t√≠pico: entre `0.6` e
`1.0`. Se voc√™ notar que a transcri√ß√£o t√° muito curta ou longa, pode brincar com
isso. Eu n√£o toquei neste argumento.

---

**`--suppress_tokens`**

Permite suprimir tokens pelo ID. O valor `-1` (padr√£o) j√° suprime s√≠mbolos
esquisitos e s√≥ mant√©m pontua√ß√µes comuns. Deixa assim, a menos que voc√™ saiba o
que est√° fazendo.

Exemplo:

```sh
# Isso aqui vai cortar algumas coisas √∫teis (s√≥ exemplo).
# Seu texto n√£o ter√°: 'Ol√°', 'pessoal', ',', 'este', '√©', 'meu', 'texto', '.'
# Obs: texto sem ponto e v√≠rgula fica horr√≠vel
whisper /caminho/do/seu/arquivo.mp4 \
    --model turbo \
    --language pt \
    --suppress_tokens=38056,842,24811,11,4065,1136,9230,35503,13
```

_Quer saber o ID de um token espec√≠fico?_

Seguinte, se voc√™ que descobrir algum token para suprimir ou para qualquer outra
coisa, veja um exemplo:

```python
>>> from whisper.tokenizer import get_tokenizer
# get_tokenizer -> multilingual, num_languages=99, language='pt', task='transcribe'
#                  True,         99                Qual idioma    Qual task
>>> tokenizer = get_tokenizer(True, num_languages=99, language='pt', task='transcribe')
# tokenizer.encode voc√™ passa o 'valor' e recebe os tokens List[int]
>>> tokenizer.encode('Ol√° pessoal, este √© meu texto.')
[38056, 842, 24811, 11, 4065, 1136, 9230, 35503, 13]
# tokenizer.decode voc√™ passa os tokens List[int] e recebe o 'valor'
>>> tokenizer.decode([38056, 842, 24811, 11, 4065, 1136, 9230, 35503, 13])
'Ol√° pessoal, este √© meu texto.'
>>>
```

---

**`--fp16`**

Usa precis√£o _float16_ para acelerar em GPU.

No Mac M1, por exemplo, eu sempre uso `--fp16 False`, assim ele n√£o fica
mostrando warning de que trocou pra _float32_. Essa troca acontece
automaticamente se o seu hardware **n√£o** suportar _float16_, ent√£o:

- **Se suportar:** passa direto com _float16_.
- **Se n√£o suportar:** ele mostra um aviso e troca para _float32_ sozinho.

Exemplo do warning:

```
FP16 is not supported on CPU; using FP32 instead
```

---

**`--compression_ratio_threshold`**

Se a raz√£o de compress√£o (gzip) do texto for muito alta, ele assume que houve
erro (textos muito repetitivos). Valor padr√£o √© `2.4`. √ötil pra detectar _loop
de repeti√ß√£o_.

**Como funciona a ideia:**

O Whisper pega o texto, compacta com gzip e compara o **tamanho original** com o
**tamanho compactado** para calcular a **raz√£o de compress√£o**. Textos
repetitivos geram compress√µes mais eficientes, ou seja, **raz√£o mais alta**.

- `"Ol√°, ol√°, ol√°, ol√°, ol√°..."` ‚Üí compacta muito ‚Üí **alta raz√£o**
- `"O rato roeu a roupa do rei de Roma."` ‚Üí mais diversidade ‚Üí **menor raz√£o**

Se a raz√£o ultrapassar o limite definido (padr√£o: `2.4`), o Whisper **descarta o
trecho** por consider√°-lo problem√°tico (repetitivo, bugado etc).

Se sua transcri√ß√£o estiver falhando **sem motivo claro**, esse filtro pode ser o
culpado. Teste com `--compression_ratio_threshold 0` e veja se melhora.

---

**`--logprob_threshold`**

Se a m√©dia do logaritmo da probabilidade (logprob) dos tokens estiver abaixo
disso, ele trata como erro. Padr√£o: `-1.0`. Voc√™ consegue ver `avg_logprob`
(m√©dia do logaritmo da probabilidade) das frases transcritas pelo Whisper no
arquivo `.json` final gerado. Este arquivo cont√©m algo similar a isso:

```json
{
  "id": 102,
  "seek": 27632,
  "start": 293.8,
  "end": 294.66,
  "text": " primeiro os imports",
  "tokens": [51240, 18314, 3003, 41596, 51283],
  "temperature": 0.0,
  "avg_logprob": -0.08265516709308235,
  "compression_ratio": 1.7523364485981308,
  "no_speech_prob": 1.1688144375965326e-11,
  "words": [
    {
      "word": " primeiro",
      "start": 293.8,
      "end": 294.06,
      "probability": 0.7435079216957092
    },
    {
      "word": " os",
      "start": 294.06,
      "end": 294.24,
      "probability": 0.9965941309928894
    },
    {
      "word": " imports",
      "start": 294.24,
      "end": 294.66,
      "probability": 0.990346372127533
    }
  ]
}
```

Aqui `avg_logprob` √© `-0.08265516709308235`. Quanto mais pr√≥ximo de `0`, mais
confiante est√° o modelo.

Suponha que o modelo est√° descartando coisas na transcri√ß√£o. Voc√™ poderia testar
`--logprob_threshold=-2.0` ou at√© `--logprob_threshold=-1000` (n√£o descarta
nada).

Isso pode gerar muito ru√≠do aleat√≥rio na transcri√ß√£o, mas pode fazer ele
detectar o que voc√™ quer.

O contr√°rio tamb√©m √© verdadeiro. Se usar `--logprob_threshold=-0.1` (por
exemplo), o modelo vai pegar praticamente s√≥ o que tem certeza absoluta que t√°
certo. Isso n√£o √© uma coisa boa ou ruim, depende do contexto e do seu objetivo.
Na d√∫vida, manter o padr√£o costuma ser uma escolha segura.

Quanto mais rigoroso, mais lento, porque ele vai tentar gerar v√°rias hip√≥teses
at√© alcan√ßar esse n√≠vel de confian√ßa. No fim das contas, ele vai te entregar um
texto de qualquer jeito, mas pode demorar bem mais e talvez nem seja t√£o
diferente assim.

---

**`--no_speech_threshold`**

Se o modelo acredita que √© sil√™ncio (probabilidade alta de `<|nospeech|>`) **e**
a decodifica√ß√£o falha (`logprob_threshold`), ele descarta o trecho como sendo
sil√™ncio. Isso ajuda a cortar "respiros vazios" da transcri√ß√£o.

Essa funcionalidade me encanta, e tenho planos futuros pra ela. Quem sabe a
gente n√£o volta a falar disso mais pra frente?

---

**`--prepend_punctuations`** (com `--word_timestamps True`):

Este argumento controla quais caracteres de pontua√ß√£o que aparecem **antes** de
uma palavra devem ser "colados" √† palavra seguinte, em vez de serem tratados
como um token separado.

- **Padr√£o**: `\"\'‚Äú¬ø([{-` (inclui aspas, par√™nteses, etc.) e requer
  `--word_timestamps True`.

Em teoria, se o modelo gerasse, por exemplo, os tokens `(`, `arg`, `ument`,
`os`, `)` separadamente (tipo: `[7, 33544, 2206, 329, 8]` que formariam
`(argumentos)`), o `(` e o `arg` seriam unidos para formar `(arg`.

> **Observa√ß√£o Importante**: eu testei o `whisper` com os idiomas `Portuguese` e
> `English` (90% em `Portuguese`, que √© meu caso de uso). Em nenhuma das
> legendas que gerei houve qualquer caso onde a pontua√ß√£o viesse antes de alguma
> palavra. Na pr√°tica, eu realmente n√£o usei este par√¢metro.

---

**`--append_punctuations`** (com `--word_timestamps True`):

Este argumento controla quais caracteres de pontua√ß√£o que aparecem **depois** de
uma palavra devem ser "colados" √† palavra anterior.

- **Padr√£o**: `\"\'.„ÄÇ,Ôºå!ÔºÅ?Ôºü:Ôºö‚Äù)]}„ÄÅ` (inclui aspas, pontos, v√≠rgulas,
  interroga√ß√µes, etc.) e requer `--word_timestamps True`.

Por exemplo, se os tokens gerados forem `Ok` e `?` separadamente, e o `?`
estiver inclu√≠do nesta lista (o que j√° est√° por padr√£o), eles ser√£o unidos para
formar `Ok?`.

**Dica Pr√°tica**: Esses argumentos de pontua√ß√£o s√≥ far√£o uma diferen√ßa
percept√≠vel se voc√™ precisar que o ponto ou outro s√≠mbolo tenha um `timestamp`
_exatamente_ separado da palavra, o que √© um caso de uso bastante espec√≠fico. Na
maioria das situa√ß√µes, o padr√£o do `whisper` j√° √© bastante robusto. Do
contr√°rio, e para simplificar, mantenha os valores padr√£o.

---

### Outros √∫teis

**`--threads`**

Define o n√∫mero de _threads_ que o modelo vai usar na CPU. Exemplo:
`--threads 4`. Se n√£o passar nada, ele usa o padr√£o da Torch (geralmente via MKL
ou OMP).

Nos meus testes (Mac M1), usei `1, 4, 10, 100, 1000`. O resultado? Ele s√≥ criou
mais _threads_ e usou mais CPU, **mas a velocidade de transcri√ß√£o n√£o mudou
absolutamente nada**.

Claro, meus testes foram superficiais. Pode ser que em outro sistema, com outra
CPU (ou invocando Cthulhu no terminal), voc√™ veja alguma diferen√ßa. Eu? S√≥ vi o
cooler suando.

---

**`--clip_timestamps`**

Permite transcrever ou traduzir apenas trechos espec√≠ficos do √°udio ou v√≠deo.
Voc√™ passa os intervalos como pares `start,end` (em segundos). Pode usar v√°rios.

**Exemplos:**

- `--clip_timestamps 10,30` ‚Üí transcreve de 10s at√© 30s
- `--clip_timestamps 60,120` ‚Üí de 1min at√© 2min
- `--clip_timestamps 10,30,60,120` ‚Üí dois trechos: 10s‚Äì30s e 1min‚Äì2min
- ‚ö†Ô∏è `--clip_timestamps 270` ‚Üí de 4min30s at√© o final
- ‚ö†Ô∏è `--clip_timestamps 60,120,0` ‚Üí transcreve de 1min‚Äì2min **e depois recome√ßa
  do zero at√© o fim**

**Aten√ß√£o:**

Esse √∫ltimo exemplo (`60,120,0`) parece um caso n√£o previsto.

O `0` vem depois de `120`, mas n√£o forma um par `start,end`.

Nos testes, isso gerou um comportamento curioso: o modelo transcreveu
normalmente de 1min at√© 2min, **e depois do in√≠cio at√© o final**.

Mesmo assim, o VLC interpretou direitinho. Ele realinhou os blocos e ignorou os
duplicados, mostrando s√≥ o que fazia sentido cronol√≥gico (**aparentemente
cortando o primeiro minuto**).

---

**`--hallucination_silence_threshold`**

Funciona junto com `--word_timestamps True`.

Ele tenta detectar trechos de sil√™ncio longos que o modelo pode ter "alucinado"
(inventado texto).

Se voc√™ passar `--hallucination_silence_threshold 1.5`, ele vai **ignorar
sil√™ncios maiores que 1.5s que geraram texto suspeito**. N√£o toquei nesse
argumento.

---

## Usando o Whisper via c√≥digo

Para usar o `whisper` via c√≥digo, √© bem simples. Como informado no reposit√≥rio
deles, basta usar o seguinte para uso normal do whisper.

```python
import whisper

model = whisper.load_model("turbo")
result = model.transcribe("audio.mp3")
print(result["text"])
```

Para um acesso de mais baixo n√≠vel:

```python
import whisper

model = whisper.load_model("turbo")

# load audio and pad/trim it to fit 30 seconds
audio = whisper.load_audio("audio.mp3")
audio = whisper.pad_or_trim(audio)

# make log-Mel spectrogram and move to the same device as the model
mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)

# detect the spoken language
_, probs = model.detect_language(mel)
print(f"Detected language: {max(probs, key=probs.get)}")

# decode the audio
options = whisper.DecodingOptions()
result = whisper.decode(model, mel, options)

# print the recognized text
print(result.text)
```

### E como eu fiz meu c√≥digo?

Eu fiz o c√≥digo de uma forma que eu continuasse usando todos os par√¢metros do
`whisper`, por√©m, adicionando minha pr√≥pria l√≥gica.

Basicamente eu simulo que os argumentos est√£o sendo enviados para mim com
`sys.argv` do Python. No Diagrama abaixo eu mostro o processo do "terminal" at√©
chegar ao `argparse`, e do lado direito, como montei meu c√≥digo tamb√©m chamando
o argparse.

<p>
    <a
        href="images/diagrama.webp"
        target="_blank"
        rel="noopener noreferrer"
    >
        <img
            src="images/diagrama.webp"
            alt="Diagrama exibindo como usei o `sys.argv` para simular o terminal no meu c√≥digo"
        />
        <em
            >Diagrama exibindo como usei o `sys.argv` para simular o terminal no meu c√≥digo</em
        >
    </a>
</p>

Veja o c√≥digo a seguir. S√≥ para constar, tem um logger em outro m√≥dulo com o
seguinte c√≥digo.

```python
import logging

from rich.logging import RichHandler

logging.basicConfig(
    level="CRITICAL",
    format="%(message)s",
    datefmt="[%H:%M]",
    handlers=[
        RichHandler(
            show_time=True,
            show_level=True,
            rich_tracebacks=True,
            omit_repeated_times=False,
            markup=False,
        )
    ],
)

logger = logging.getLogger("rich")
```

Agora sim, vamos ver o c√≥digo. Deixei v√°rios coment√°rio explicando tudo.

```python
import argparse
from pathlib import Path

import rich_argparse

from sussu.basic_logger import logger

# Example commands:
#
# sussu whisper ~/Desktop/videos/part_0004.mp4 --temperature 0 --beam_size 1 \
# --device cpu --fp16 False --output_format srt --model tiny --language pt \
# --output_dir ~/Desktop/videos/
#
# sussu one ~/Desktop/videos/part_0004.mp4 --temperature 0 --beam_size 1 \
# --device cpu --fp16 False --output_format srt --model tiny --language pt \
# --output_dir ~/Desktop/videos/
#
# sussu batch --input_dir ~/Desktop/videos/ --temperature 0 --beam_size 1
# --device cpu --fp16 False --output_format srt --model tiny --language pt
# -s video.mp4 part_0000.mp4 --skip_files part_0001.mp4
# --output_dir 'this wont do anything here'


# Essa fun√ß√£o √© basicamente um jeito de "enganar" o cli do `whisper`
# para que ele "entenda" que est√° sendo chamado com determinados argumentos.
def whisper_cli_runner(whisper_args: list[str]) -> None:
    import sys

    # `whisper` n√£o tem stub, por isso o pyright vai gerar erro (ignorado)
    from whisper.transcribe import cli as whisper_cli  # pyright: ignore

    # Aqui est√° a mal√≠cia. Vamos fingir que o python est√° recebendo os argumento
    # via sys.argv. Com isso o argparse entra em a√ß√£o da mesma forma que
    # entraria se estivesse sendo executado via linha de comando.
    sys.argv = ["whisper", *whisper_args]
    whisper_cli()


# Essa √© a nossa fun√ß√£o que vai processar os arquivos usando o whisper original
def batch_whisper(
    input_dir: Path, whisper_raw_args: list[str], skip_files: list[str] | None = None
) -> None:
    # Vamos preencher essa lista com os dados que precisamos
    whisper_args: list[str] = []

    # As extens√µes abaixo podem n√£o conter todas as extens√µes suportadas pelo
    # ffmpeg, sinta-se √† vontade para adicionar novas extens√µes
    # fmt: off
    allowed_extensions =  {
        ".mp3", ".wav", ".flac", ".aac", ".m4a", ".ogg", ".opus", ".mp4", ".mkv",
        ".webm", ".mov", ".avi", ".3gp", ".wmv",
    }
    # fmt: on

    # √Äs vezes tem alguns arquivos na mesma pasta que s√£o v√°lidos, mas n√£o
    # queremos transcrever (eu s√≥ queria agilizar meus testes manuais)
    if not skip_files:
        skip_files = []

    # Passamos em todos os arquivos da pasta enviada pelo usu√°rio
    for file in input_dir.iterdir():
        skip_loop = False
        ########## VAMOS PULAR ALGUNS ARQUIVOS PARA EVITAR ERROS ##########

        # Pulamos quando √© um subdiret√≥rio
        if file.is_dir():
            logger.warning(f"Directory not allowed: {file.name}")
            continue

        # Pulamos se a extens√£o n√£o for permitida
        if file.suffix not in allowed_extensions:
            logger.error(f"File extension not allowed: {file.name}")
            continue

        # Pulamos tamb√©m quando o usu√°rio pede para pular aquele arquivo via -s
        for skip_file in skip_files:
            if str(file).endswith(skip_file):
                logger.info(f"File skipped: {file.name}")
                skip_loop = True

        if skip_loop:
            skip_loop = False
            continue

        ############ DAQUI EM DIANTE VAI PARA O WHISPER ##########

        # O argumento posicional vai sozinho no primeiro √≠ndice
        # depois os argumentos desconhecidos
        whisper_args.extend([str(file), *whisper_raw_args])
        logger.debug(f"audio set as {file!s}")

        # Por fim, adicionamos o outdir para ser sempre a pasta onde est√°
        # o arquivo original. Isso gera um arquivo de mesmo nome com a extens√£o
        # `.srt`.
        logger.debug(f"--output_dir set to {file.parent}")
        whisper_args.extend(["--output_dir", str(file.parent)])

        # Desativa o modo verboso do `whisper` por padr√£o para que a gente possa
        # ver nossos logs. Se o user passar algo, usa o que ele passar.
        if "--verbose" not in whisper_args:
            whisper_args += ["--verbose", "False"]
            logger.debug("--verbose set to False by default")

        # Agora s√≥ chamar o whisper com os argumentos que montamos
        logger.debug(f"whisper commands are: {whisper_args}")
        logger.debug(f"Final command: whisper {' '.join(whisper_args)}")
        whisper_cli_runner(whisper_args)

        # Zeramos os argumentos para o pr√≥ximo loop
        whisper_args = []


def build_argparse() -> argparse.ArgumentParser:
    # Nosso main parser e o subparser para os comandos
    parser = argparse.ArgumentParser(
        prog="sussu", formatter_class=rich_argparse.RawDescriptionRichHelpFormatter
    )
    subparsers = parser.add_subparsers(dest="command", required=True)

    ########## WHISPER PARSER ##########

    # Esse subparse s√≥ ser√° usado como um wrapper do argparse do whisper.
    # No final das contas, ele s√≥ vai chamar `whisper.transcribe.cli()`
    whisper_parser = subparsers.add_parser(
        "whisper",
        help="Calls `whisper` directly",
        conflict_handler="resolve",
        aliases=["one"],
        formatter_class=rich_argparse.RawDescriptionRichHelpFormatter,
    )
    whisper_parser.set_defaults(command="whisper")

    # Esse argumento aqui √© pra garantir que vamos chamar o help do whisper e
    # n√£o do nosso parser
    whisper_parser.add_argument(
        "-h", "--help", help="Shows `whisper` help.", action="store_true"
    )

    ########## NOSSOS PARSERS ##########
    # Minha ideia aqui √© criar um subparser `batch` que vai receber um diret√≥rio
    # com arquivos de v√≠deo. Vamos passar em todos os arquivos do diret√≥rio e
    # usar o whisper para transcrever cada um deles.

    batch_parser = subparsers.add_parser(
        "batch",
        help="Process files with `whisper` in batch mode",
        formatter_class=rich_argparse.RawDescriptionRichHelpFormatter,
    )

    # S√≥ coloquei essa fun√ß√£o aqui para ficar pr√≥xima do argumento e facilitar
    # minha explica√ß√£o na hora de gravar.
    def parse_input_dir(path_str: str) -> Path:
        path = Path(path_str)

        if not path.is_dir():
            msg = f"{path_str!r} is not a directory"
            raise argparse.ArgumentTypeError(msg)

        return path.resolve()

    # Isso dever√° ser uma pasta que cont√©m arquivos de v√≠deo ou √°udio
    batch_parser.add_argument(
        "--input_dir",
        help="Directory with files to work with",
        type=parse_input_dir,
        required=True,
    )

    # Para testar, eu estava pulando um monte de arquivos para ir mais r√°pido
    batch_parser.add_argument(
        "-s",
        "--skip_files",
        help="Name of file(s) to skip",
        action="extend",
        nargs="+",
        default=[],
    )

    # Essa foi a maneira mais simples e direta de remover output_dir dos
    # unknown_args. Se isso fosse para o whisper, geraria conflito
    batch_parser.add_argument("-o", "--output_dir", help=argparse.SUPPRESS)
    return parser


def run() -> None:
    ########## PARSE KNOWN ARGS ##########

    # Vamos receber argumentos que s√£o conhecidos (os nossos), e desconhecidos.
    # Argumentos desconhecidos ser√£o repassados para o whisper cli.
    parser = build_argparse()
    args, unknown_args = parser.parse_known_args()

    # Se o comando for whisper, passamos tudo direto para o whisper
    if args.command == "whisper":
        # Simula -h e --help
        if args.help:
            whisper_cli_runner(["--help"])
            return

        # Executa o whisper normal, s√≥ que por baixo de `sussu`
        # Ex.: `sussu whisper audio.mp3` chama o cli original do `whisper` com
        # o argumento `audio.mp3` (ou qualquer outro argumento)
        whisper_cli_runner(unknown_args)
        return

    # Se o comando for `batch`, fazemos nosso trabalho
    if args.command == "batch":
        batch_whisper(args.input_dir, unknown_args, args.skip_files)


if __name__ == "__main__":
    run()
```

√â s√≥ isso! Obrigado por ler.

---





    </script>
    <!-- prettier-ignore -->

    <!-- Markdown parser -->
    <script defer src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/marked-gfm-heading-id/lib/index.umd.js"></script>

    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script defer src="../../js/scripts.js"></script>
  </body>
</html>
