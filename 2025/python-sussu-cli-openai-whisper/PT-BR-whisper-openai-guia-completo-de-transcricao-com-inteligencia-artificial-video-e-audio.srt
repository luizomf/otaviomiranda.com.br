1
00:00:00,000 --> 00:00:04,520
Fala aí, pessoal! Já ative a legenda desse
vídeo aí, que você vai ver em tempo real o

2
00:00:04,520 --> 00:00:08,200
que eu tô falando. É óbvio, né? Isso é uma
legenda, mas essa legenda, ela é mais

3
00:00:08,200 --> 00:00:12,440
especial porque ela foi gerada por esse
cara aqui, que é o Whisper da OpenAI, que é

4
00:00:12,440 --> 00:00:17,020
um modelo de inteligência artificial da
OpenAI que vai, basicamente, fazer

5
00:00:17,020 --> 00:00:20,240
reconhecimento de fala e, através desse
reconhecimento de fala, ele consegue fazer

6
00:00:20,240 --> 00:00:24,000
várias coisas; por exemplo, fazer a
transcrição desse vídeo, que é a legenda

7
00:00:24,000 --> 00:00:27,400
que você tá vendo aí, ou até fazer a
tradução. Eu vou ver depois se eu faço a

8
00:00:27,400 --> 00:00:32,260
tradução dessa transcrição, então para que
eu tenha duas transcrições: eu tenho uma

9
00:00:32,260 --> 00:00:35,560
legenda em português e uma legenda do que
eu tô falando, que é mais comum a gente

10
00:00:35,560 --> 00:00:40,680
ver; legenda em um idioma diferente, vai
ser uma legenda para inglês, por exemplo.

11
00:00:40,900 --> 00:00:45,060
Depois a gente fala sobre isso. Então, o
que a gente vai falar nesse vídeo, só para

12
00:00:45,060 --> 00:00:47,920
você entender, caso você queira, tipo: "Eu
quero ver esse vídeo ou eu quero ver o

13
00:00:47,920 --> 00:00:50,840
outro", porque eu vou dividir isso aqui em
duas partes. Primeiro, o Whisper, ele

14
00:00:50,840 --> 00:00:54,700
funciona como uma ferramenta de linha de
comando. Então, eu vou focar na ferramenta

15
00:00:54,700 --> 00:00:57,820
de linha de comando, porque se a gente
olhar aqui, só de você olhar o tamanho

16
00:00:57,820 --> 00:01:02,020
dessa coisa que eu escrevi aqui, você vai
ver a quantidade de informações que a

17
00:01:02,020 --> 00:01:05,660
gente tem aqui só com a ferramenta de
linha de comando. E aí, depois eu vou te

18
00:01:05,660 --> 00:01:09,220
mostrar no próximo vídeo como fazer a
implementação de um código utilizando o

19
00:01:09,220 --> 00:01:12,440
Whisper. E aí você consegue embutir isso
dentro do seu código e colocar, sei lá, no

20
00:01:12,440 --> 00:01:17,200
seu Django, na onde você quiser trabalhar
com o Whisper. É só você utilizar da parte

21
00:01:17,200 --> 00:01:21,120
do outro vídeo lá. Então, como eu te falei,
a gente vai focar basicamente na linha de

22
00:01:21,120 --> 00:01:24,680
comando do Whisper aqui. Uma outra
curiosidade para você: é porque eu tenho

23
00:01:24,680 --> 00:01:30,880
utilizado já o Whisper por, basicamente, uns
seis meses aqui, e eu tenho percebido que

24
00:01:30,880 --> 00:01:34,800
os pontos fortes e os pontos fracos dele,
que eu vou te falar aqui no vídeo, mas

25
00:01:34,800 --> 00:01:38,400
quando eu fui escrever isso, me deu uma
curiosidade absurda em saber se a OpenAI

26
00:01:38,400 --> 00:01:42,560
utilizava isso internamente. Então, a única
coisa que eu pensei foi perguntar para o

27
00:01:42,560 --> 00:01:46,760
ChatGPT se ele poderia me informar. Eu
perguntei isso aqui para o ChatGPT: "A

28
00:01:46,760 --> 00:01:51,200
OpenAI usa o Whisper internamente em algum
recurso que as pessoas consomem?". Por

29
00:01:51,200 --> 00:01:55,160
curiosidade, ele me respondeu — não sei se
é verdade, mas me respondeu sim — a OpenAI

30
00:01:55,160 --> 00:01:59,600
usa o Whisper como base para recursos de
transcrição e compreensão de áudio em

31
00:01:59,600 --> 00:02:04,420
produtos como o ChatGPT com entrada de
voz. Ele também é utilizado em APIs que

32
00:02:04,420 --> 00:02:10,220
envolvem reconhecimento de fala, como o
Speech-to-Text da OpenAI. Então, você vê

33
00:02:10,220 --> 00:02:15,320
que ele é um modelo de inteligência
artificial gratuito, open source, e que é

34
00:02:15,320 --> 00:02:19,720
usado por uma empresa enorme aqui e super
famosa também. Então, por isso que eu acho

35
00:02:19,720 --> 00:02:23,200
que ele é tão bom assim. Mas o que a gente
vai falar então nesse vídeo vai ser

36
00:02:23,200 --> 00:02:27,920
basicamente a parte da linha de comando do
Whisper, que a gente começa agora. Eu vou

37
00:02:27,920 --> 00:02:31,000
Usar esse trecho que eu falei até agora,
que para mim está dando mais ou menos uns

38
00:02:31,000 --> 00:02:35,220
3 minutos, esse trecho que eu falei que
agora eu vou cortar e vou usar nos

39
00:02:35,220 --> 00:02:39,300
nossos exemplos. Beleza? Então, se você
lembrar o que eu falei desde o começo do

40
00:02:39,300 --> 00:02:42,760
vídeo, você consegue perceber na legenda,
porque eu não vou ficar dando replay no

41
00:02:42,760 --> 00:02:45,860
vídeo. Então, você pode voltar no começo,
ver o que eu falei e ver se ele está

42
00:02:45,860 --> 00:02:50,100
acertando o que eu falei aqui na
transcrição de vídeo. Beleza? Então, bora

43
00:02:50,100 --> 00:02:54,500
lá começar com isso aqui. Então pronto,
pessoal, eu já fiz a introdução e já

44
00:02:54,500 --> 00:02:58,800
passei essa introdução dentro de um outro
script Python que faz o corte de

45
00:02:58,800 --> 00:03:03,540
silêncio automaticamente do vídeo para
mim. Esse corte cortou mais de 30

46
00:03:03,540 --> 00:03:07,220
segundos do áudio, talvez eu tenha ficado
em silêncio muito tempo no começo do vídeo

47
00:03:07,220 --> 00:03:10,480
ou no final do vídeo, alguma coisa assim.
Ele já cortou esse áudio, ele foi para

48
00:03:10,480 --> 00:03:14,320
mais ou menos 2 minutos e 30 segundos.
Então, é isso que a gente vai utilizar. Eu coloquei

49
00:03:14,320 --> 00:03:19,540
o nome de one-auto.mp4, para falar, essa é a
primeira parte do vídeo e também ele foi

50
00:03:19,540 --> 00:03:23,720
cortado automaticamente para mim. Além
disso, a gente precisa entender como é que

51
00:03:23,720 --> 00:03:28,300
a gente vai rodar o Whisper aqui. O que eu
fiz? Eu coloquei aqui esse código num

52
00:03:28,300 --> 00:03:32,940
repositório que vai chamar de `sussu`, `sussu`
(rro), no caso. Então, o comando da gente

53
00:03:32,940 --> 00:03:37,240
ali vai ser `sussu`. E também tem um
repositório oficial do Whisper, caso você

54
00:03:37,240 --> 00:03:41,040
queira olhar. Eu até deixei um
negócio aqui aberto também, que foi isso

55
00:03:41,040 --> 00:03:45,600
aqui, para você entender que a transcrição
de vídeo pode ser utilizada para várias

56
00:03:45,600 --> 00:03:50,460
coisas inteligentes e interessantes
também. Por exemplo, eu utilizo as

57
00:03:50,460 --> 00:03:54,840
transcrições do vídeo para passar essa
transcrição dentro de uma outra API, por

58
00:03:54,840 --> 00:03:59,800
exemplo, do Gemini ou do ChatGPT, do GPT-4
ou qualquer GPT que você quiser

59
00:03:59,800 --> 00:04:04,100
utilizar. Mas eu passo essa transcrição em
uma inteligência artificial que ela gera

60
00:04:04,100 --> 00:04:09,140
para mim resumos de trechos. Então, eu
mando um chunk da legenda, um trecho da

61
00:04:09,140 --> 00:04:13,560
legenda, para dentro de uma API qualquer
de inteligência artificial e passo um

62
00:04:13,560 --> 00:04:17,240
prompt falando o que eu quero que ela
faça. Nesse caso aqui, é o vídeo do

63
00:04:17,240 --> 00:04:20,920
argparse que a gente falou do Python.
Ele tem uma hora e meia. Então, eu corto

64
00:04:20,920 --> 00:04:25,340
em pedacinhos de sete minutos a legenda,
passo para o Gemini e aí peço para ele,

65
00:04:25,420 --> 00:04:29,040
através de um prompt, fazer um
resumo do que eu falei naquele trecho. E

66
00:04:29,040 --> 00:04:32,060
aí ele vai fazendo, vai falando as
ferramentas que eu utilizei e é super

67
00:04:32,060 --> 00:04:35,700
preciso. Olha só, aqui ele está falando
que o objetivo principal desse trecho é

68
00:04:35,700 --> 00:04:40,000
introduzir um tutorial sobre como usar o
argparse do Python para criar ferramentas

69
00:04:40,000 --> 00:04:44,620
de linha de comando. O apresentador propõe
um desafio prático, construir a interface

70
00:04:44,620 --> 00:04:48,620
de linha de comando CLI para um projeto
existente, permitindo a comunicação externa

71
00:04:48,620 --> 00:04:52,720
com o programa. Se você assistir a esse
vídeo, você vai ver que é exatamente isso

72
00:04:52,720 --> 00:04:55,780
aqui que eu falo lá naquele vídeo. E aí
ele mostra quais as ferramentas que eu

73
00:04:55,780 --> 00:04:59,140
Utilizei, detalha as ferramentas, mostra
os passos que eu segui até esse

74
00:04:59,140 --> 00:05:03,020
determinado trecho aqui, e aí dá algumas
dicas aqui embaixo e assim por diante. E

75
00:05:03,020 --> 00:05:06,640
ele vai fazendo isso aqui através dos
trechos, através de um for ali, eu vou

76
00:05:06,640 --> 00:05:10,760
mandando os pedaços de legenda para ele, e
aí ele vai gerando isso aqui. No final,

77
00:05:10,920 --> 00:05:14,320
você pode pedir para ele fazer o que você
quiser. Por exemplo, eu já usei o Gemini

78
00:05:14,320 --> 00:05:19,200
para fazer a tradução para outro idioma.
Por exemplo, o Whisper faz isso, mas eu

79
00:05:19,200 --> 00:05:24,340
vou te explicar aqui o motivo do porquê eu
utilizei o Gemini. Mas eu já utilizei para

80
00:05:24,340 --> 00:05:29,560
fazer a tradução dessa legenda minha para
inglês ou para outro idioma, espanhol, e

81
00:05:29,560 --> 00:05:33,720
aí ele gera vários idiomas daquela mesma
transcrição para você. Eu também já

82
00:05:33,720 --> 00:05:37,840
utilizei o Gemini para fazer um resumo
geral do que eu falei no vídeo em forma de

83
00:05:37,840 --> 00:05:42,700
artigo. Fica muito bom também. E eu também
já utilizei isso para escrever, e isso eu

84
00:05:42,700 --> 00:05:46,920
utilizo até hoje, que é para escrever a
descrição do vídeo, os capítulos aqui,

85
00:05:47,000 --> 00:05:51,080
essa parte aqui. O resultado final,
conteúdo para o YouTube. Capítulos para o

86
00:05:51,080 --> 00:05:54,240
vídeo, isso eu pedi para ele, aí ele gera
os capítulos. Beleza, depois eu pedi para

87
00:05:54,240 --> 00:06:00,040
ele fazer um SEO otimizado aqui para mim,
e aí ele fez ali a descrição do vídeo. Eu

88
00:06:00,040 --> 00:06:03,420
esqueci de colocar o título aqui, mas ele
faz também o título, coloca keywords e

89
00:06:03,420 --> 00:06:06,320
assim por diante. Então eu estou te
mostrando isso aqui só para você ver que

90
00:06:06,320 --> 00:06:11,260
fazer a transcrição de um vídeo é super
poderoso porque te dá o texto do que você

91
00:06:11,260 --> 00:06:16,020
falou. E a partir desse texto você pode
fazer o que você quiser com esse texto ali

92
00:06:16,020 --> 00:06:20,860
para o seu vídeo. Gerar um post, traduzir,
gerar post em outro idioma, enfim, o que

93
00:06:20,860 --> 00:06:24,440
você quiser. O que você conseguir
imaginar, você consegue fazer com o texto

94
00:06:24,440 --> 00:06:28,580
do seu vídeo ali. Beleza, dito isso, o
Whisper aqui, só para você entender

95
00:06:28,580 --> 00:06:32,500
melhor, ele utiliza este formato aqui. Por
que eu vou te mostrar isso aqui? Porque

96
00:06:32,500 --> 00:06:35,380
isso aqui é super nerd, mas eu vou te
mostrar isso aqui só para você entender

97
00:06:35,380 --> 00:06:39,000
como é que ele funciona. E eu também vou
te passar dicas aqui, os pontos fortes e

98
00:06:39,000 --> 00:06:41,980
os pontos fracos dele, que eu tenho
utilizado ele há bastante tempo já, então

99
00:06:41,980 --> 00:06:45,720
consigo te falar essas coisas. Mas
inicialmente o que ele faz? Quando você

100
00:06:45,720 --> 00:06:51,060
passa um áudio, a gente fala em áudio, mas
como o Whisper utiliza o FFmpeg, que é

101
00:06:51,060 --> 00:06:55,420
uma... A gente chega nisso, mas o Whisper
utiliza o FFmpeg. Isso quer dizer que você

102
00:06:55,420 --> 00:07:00,140
pode passar direto um vídeo para ele, que
o código do Whisper que a OpenAI escreveu

103
00:07:00,140 --> 00:07:06,940
lá já faz a conversão desse vídeo em áudio
e desse áudio em um log-mel espectrograma.

104
00:07:07,240 --> 00:07:12,540
Palavra difícil, mas é basicamente o
seguinte: o Whisper não ouve áudio, ele vê

105
00:07:12,540 --> 00:07:16,920
uma imagem que representa esse áudio, um
gráfico aqui, esse espectrograma aqui, que

106
00:07:16,920 --> 00:07:22,500
utiliza a escala logarítmica Mel, é um
negócio super nerd aqui, que para você

107
00:07:22,500 --> 00:07:26,960
entender você teria que ser engenheiro de
áudio, matemático e nerd tudo ao mesmo

108
00:07:26,960 --> 00:07:30,880
tempo, então é um negócio meio complicado.
Mas o Whisper não ouve áudio, ele vê a

109
00:07:30,880 --> 00:07:36,020
Imagem do que você falou, e essa imagem é
separada em trechos de 30 segundos. Então

110
00:07:36,020 --> 00:07:40,680
ele pega o seu texto original, seu áudio
original, quebra essas partes em partes de

111
00:07:40,680 --> 00:07:44,840
30 segundos, passa essas partes por dentro
do Whisper, e aí ele faz tudo o que ele

112
00:07:44,840 --> 00:07:49,800
precisa fazer ali. Aqui também tem o fluxo
completo, caso você queira ver, porque o

113
00:07:49,800 --> 00:07:54,240
Whisper não faz só transcrição de áudio e
tradução de áudio, ele também faz o

114
00:07:54,240 --> 00:08:00,500
seguinte: ele pode fazer o reconhecimento
de fala em multilínguas, ou seja, multi-

115
00:08:00,500 --> 00:08:05,340
idiomas; ele consegue fazer isso, ele
consegue fazer a tradução da fala, só que

116
00:08:05,340 --> 00:08:09,440
essa tradução da fala dele é só para
inglês. Então você fala alguma coisa em

117
00:08:09,440 --> 00:08:14,100
qualquer idioma, pede para ele fazer, ao
invés de transcrição, a tradução; essa

118
00:08:14,100 --> 00:08:18,420
tradução, ela vai do seu idioma para inglês
somente. Se você quiser fazer em outro

119
00:08:18,420 --> 00:08:22,340
idioma, por isso eu utilizei o Gemini; se
você quiser fazer em outro idioma, você

120
00:08:22,340 --> 00:08:27,760
pode utilizar também o NLLB, que é "No
Languages Left Behind", se eu não me

121
00:08:27,760 --> 00:08:33,460
engano, que traduz de idioma para idioma
para 200 idiomas, no caso. Eu fiz isso já

122
00:08:33,460 --> 00:08:41,180
utilizando isso aqui, que é o NLLB,
que é isso aqui. Isso aqui eu já fiz há

123
00:08:41,180 --> 00:08:44,720
algum tempo; se você quiser, eu trago um
tutorial. Ele usa o Whisper e o NLLB para

124
00:08:44,720 --> 00:08:48,740
fazer exatamente isso: ele faz a
transcrição do áudio, no caso, e faz também

125
00:08:48,740 --> 00:08:53,040
a tradução para qualquer idioma que você
quiser. Mas também você pode utilizar, se

126
00:08:53,040 --> 00:08:56,400
você quiser um negócio mais robusto, vai
ter que pagar um pouquinho para isso, mas

127
00:08:56,400 --> 00:08:59,440
você pode utilizar o Gemini, como foi o
caso do que eu te mostrei mais para trás.

128
00:08:59,440 --> 00:09:04,620
Beleza, mas voltando aqui no Whisper, ele
faz o reconhecimento, a tradução, no caso,

129
00:09:04,960 --> 00:09:09,920
ele também consegue identificar qual
idioma aquele áudio está sendo falado;

130
00:09:09,980 --> 00:09:13,160
isso aqui é legal também, se você quiser
criar algum programa somente para fazer

131
00:09:13,160 --> 00:09:16,420
reconhecimento de qual idioma está sendo
falado ali. Você pode fazer isso aqui,

132
00:09:16,720 --> 00:09:19,680
você pode fazer também — eu já tinha
pensado nisso, mas eu não fiz isso ainda —,

133
00:09:19,960 --> 00:09:24,660
mas você pode fazer também, se várias
pessoas estiverem falando em algum vídeo e

134
00:09:24,660 --> 00:09:28,700
a cada hora do vídeo elas estiverem
falando em determinados idiomas, você

135
00:09:28,700 --> 00:09:32,460
poderia fazer o Whisper fazer esse
reconhecimento e trocar o idioma para ele

136
00:09:32,460 --> 00:09:35,540
começar a traduzir em outro idioma. Ele
não faz isso automaticamente; teria que

137
00:09:35,540 --> 00:09:40,000
escrever um código para isso. E ele também
consegue — isso aqui é uma parte que eu

138
00:09:40,000 --> 00:09:43,840
estou de olho nessa parte aqui —, que é o
seguinte: ele consegue fazer o negócio que

139
00:09:43,840 --> 00:09:49,700
é chamado de Voice Activity Detection ou
VAD, essa detecção de atividade de voz,

140
00:09:49,820 --> 00:09:54,220
ela consegue, por exemplo, saber onde uma
pessoa fala ou onde uma pessoa não fala;

141
00:09:54,640 --> 00:09:57,880
então isso seria muito útil para eu
utilizar um negócio que eu utilizo aqui

142
00:09:57,880 --> 00:10:01,820
que não é muito perfeito. Eu já fiz isso
no vídeo que eu gravei na introdução, que

143
00:10:01,820 --> 00:10:06,060
é basicamente cortar silêncios do vídeo;
se eu ficar quieto, eu quero que ele corte

144
00:10:06,060 --> 00:10:09,560
aquele trecho. Então, se eu fizer assim,
você não deve ter visto isso, porque eu

145
00:10:09,560 --> 00:10:13,500
Fiquei em silêncio por mais ou menos uns 5
segundos, mas o corte aconteceu aqui nesse

146
00:10:13,500 --> 00:10:18,620
vídeo, e isso foi feito automaticamente
aqui com o auto-editor. Depois eu te

147
00:10:18,620 --> 00:10:22,020
mostro isso aqui também, se você quiser um
tutorial sobre isso. Mas isso aqui, usando

148
00:10:22,020 --> 00:10:25,420
inteligência artificial, ficaria muito
mais preciso, porque o que eu utilizo

149
00:10:25,520 --> 00:10:31,060
utiliza basicamente as ondas sonoras ali,
não é inteligência artificial, mas daria

150
00:10:31,060 --> 00:10:34,620
para fazer isso com o Whisper, se você
quisesse. E aí uma coisa importante sobre

151
00:10:34,620 --> 00:10:38,240
o Whisper. Você pode ler aqui na
documentação dele, mas eu já escrevi isso

152
00:10:38,240 --> 00:10:44,160
aqui para a gente. O Whisper utiliza por
baixo dos panos o FFmpeg, então eu deixei

153
00:10:44,160 --> 00:10:47,240
aqui nesse texto; eu vou deixar esse texto
inteiro na descrição do vídeo para você,

154
00:10:47,300 --> 00:10:50,380
para você ler exatamente o que eu estou
mostrando aqui para você, e aí você vai ter

155
00:10:50,380 --> 00:10:56,040
esses comandos todos aí, mas ele utiliza o
FFmpeg, então você deve instalar primeiro

156
00:10:56,040 --> 00:11:01,260
o FFmpeg para depois você continuar
utilizando o Whisper. Eu deixei aqui os

157
00:11:01,260 --> 00:11:05,940
comandos para Debian, para Arch Linux,
para MacOS, para Windows, de várias formas

158
00:11:05,940 --> 00:11:10,500
diferentes. Você pode utilizar esses
comandos aqui para instalar o FFmpeg. E

159
00:11:10,500 --> 00:11:15,380
também eu já fiz esse repositório aqui do
`sussu` (sussurro), que eu criei aqui,

160
00:11:15,700 --> 00:11:19,740
que é basicamente utilizando o `uv` para
subir esse repositório. Então a única

161
00:11:19,740 --> 00:11:24,060
coisa que você precisa fazer é `git clone`,
clonar esse repositório, entrar na pasta

162
00:11:24,060 --> 00:11:29,040
do que foi clonado e dar `uv sync`. Claro,
você vai precisar da `uv` para gerenciar os

163
00:11:29,040 --> 00:11:33,160
pacotes. Eu já deixei um tutorial aqui que
eu já gravei explicando como utilizar a

164
00:11:33,160 --> 00:11:37,120
`uv`. Então pronto, depois que você fez
isso, outra coisa que é importante que eu

165
00:11:37,120 --> 00:11:42,700
acabei de ver, o `uv` vai fazer isso aqui
para você, baixar e instalar o Python 3

166
00:11:42,700 --> 00:11:46,240
.11, isso é super importante por conta de
compatibilidade com o Whisper, se você

167
00:11:46,240 --> 00:11:49,880
tiver com uma versão muito alta do Python,
não vai instalar, e vai criar o seu

168
00:11:49,880 --> 00:11:53,380
ambiente virtual, vai instalar os pacotes
necessários, buildar tanto o Whisper

169
00:11:53,380 --> 00:11:58,740
quanto o `sussu`. Depois que você fizer isso
aqui, o `uv sync`, você já vai ter o projeto

170
00:11:58,740 --> 00:12:03,220
pronto, que a gente pode vir aqui e fazer
rodar ele pela primeira vez. Então aqui eu

171
00:12:03,220 --> 00:12:06,920
já tô com aquele projeto lá pronto, vou
até tirar o pin disso aqui, e eu vou

172
00:12:06,920 --> 00:12:12,020
utilizar aqui; eu já usei o `uv sync` aqui,
já fiz isso no caso nesse projeto, e daí

173
00:12:12,020 --> 00:12:15,680
ele já sincronizou tudo ali, e daí agora a
gente pode rodar pela primeira vez. Para a

174
00:12:15,680 --> 00:12:18,680
gente rodar pela primeira vez, a gente
pode tanto rodar, ou nesse caso aqui, eu

175
00:12:18,680 --> 00:12:23,220
vou sair do terminal só para você ver;
nesse caso aqui o meu editor já ativa o

176
00:12:23,220 --> 00:12:27,620
meu ambiente virtual automaticamente. Tá
vendo? Se o seu não fizer isso, você pode

177
00:12:27,620 --> 00:12:31,580
ou ativar manualmente o ambiente virtual.
Então eu já falei sobre isso, não vou

178
00:12:31,580 --> 00:12:35,980
focar nisso, mas você pode ou ativar o seu
ambiente virtual manualmente, ou você pode

179
00:12:35,980 --> 00:12:41,280
utilizar `uv run` e rodar o Whisper. Nesse
caso aqui eu já coloquei isso aqui para


180
00:12:41,280 --> 00:12:45,000
Gente, ou você pode usar assim: `uv run whisper`, ou se você ativou o ambiente

181
00:12:45,000 --> 00:12:49,580
virtual, direto comando do Whisper aqui.
Então, Whisper, e aí você vai ver o porquê

182
00:12:49,580 --> 00:12:54,000
que esse vídeo talvez fique bem grande,
né? Olha a quantidade de opções que você

183
00:12:54,000 --> 00:12:57,720
tem aqui no Whisper. Então você tem o
áudio, o áudio que está falando, fala em

184
00:12:57,720 --> 00:13:01,180
`audio file` aqui, mas pode ser vídeo
também. Vou te mostrar aqui tudo em vídeo,

185
00:13:01,620 --> 00:13:05,200
mas você tem esse `help`, você tem o `model`,
você tem todas essas opções aqui que eu

186
00:13:05,200 --> 00:13:08,860
falei de todas nesse artigo, inclusive eu
falei para você aqui de algumas que eu

187
00:13:08,860 --> 00:13:08,860
acho que você pode usar, mas você tem que
usar o modo de rodamento, que é o modo de

188
00:13:08,860 --> 00:13:08,860
rodamento, que é o modo de rodamento, que
é o modo de rodamento, que é o modo de

189
00:13:08,860 --> 00:13:09,220
rodamento, que é o modo de rodamento, que
é o modo de rodamento, que é o modo de

190
00:13:09,220 --> 00:13:11,380
rodamento. Olha, essa aqui eu nunca nem
usei e não sei nem para que serve,

191
00:13:11,480 --> 00:13:14,680
assim, eu falei para que que serve, mas eu
falei, eu não usei isso aqui. Mas vamos

192
00:13:14,680 --> 00:13:18,460
lá, quais são os argumentos que eu mais
utilizo no Whisper aqui? Primeira coisa, o

193
00:13:18,460 --> 00:13:22,100
áudio. Esse áudio, conforme eu te falei,
pode ser também um vídeo. Então, se eu

194
00:13:22,100 --> 00:13:26,600
digitar `whisper`, o caminho do meu arquivo
aqui, por exemplo, `whisper`, eu vou pegar

195
00:13:26,600 --> 00:13:30,880
aqui o áudio, o primeiro vídeo aqui que eu
gravei, que eu chamei de `one-auto.mp4`. Se eu

196
00:13:30,880 --> 00:13:33,900
mandar isso aqui para ele, eu não estou
mandando muita informação, só estou falando

197
00:13:33,900 --> 00:13:37,800
para ele assim: olha, é `whisper`, está aqui o
áudio. O áudio, na verdade, que eu estou

198
00:13:37,800 --> 00:13:42,500
mandando é um vídeo MP4 da introdução. O
FFmpeg já vai fazer o carregamento desse

199
00:13:42,500 --> 00:13:47,500
áudio, vai tirar o áudio de dentro desse
vídeo e aí tem um código aqui no Whisper,

200
00:13:47,600 --> 00:13:52,460
que você pode ver aqui na documentação
mesmo, que ele utiliza isso aqui, por

201
00:13:52,460 --> 00:13:56,760
exemplo, `load_audio` vai carregar o áudio,
por exemplo, e daí ele vai fazer isso,

202
00:13:56,860 --> 00:14:01,280
essa função, vai utilizar essa função aqui
e essa função vai converter esse áudio em

203
00:14:01,280 --> 00:14:06,600
um trecho de 30 segundos. E aí, depois
disso, ele vai fazer aquele espectrograma

204
00:14:06,600 --> 00:14:11,880
log-mel, ele vai fazer aquele
espectrograma e vai passar para dentro do

205
00:14:11,880 --> 00:14:16,220
`model` aqui. Aí o `model` vai detectar o
idioma, detectou o idioma para ele aqui,

206
00:14:16,340 --> 00:14:20,400
ele vai fazer o decode das opções que você
passou para ele aqui, e depois ele vai

207
00:14:20,400 --> 00:14:26,220
fazer o decode utilizando o `model`, que é o
modelo que você escolheu, o gráfico lá,

208
00:14:26,280 --> 00:14:29,800
aquele gráfico que eu te mostrei, porque o
Whisper não ouve, ele vê o áudio, e as

209
00:14:29,800 --> 00:14:33,720
opções, e daí ele te dá um resultado aqui
em texto. A gente também vai utilizar

210
00:14:33,720 --> 00:14:37,140
dessa forma aqui, que é bem mais prático,
no caso, que é basicamente você mandar ele

211
00:14:37,140 --> 00:14:40,980
usar esse modelo aqui especificamente,
fazer a transcrição e pegar o texto. A

212
00:14:40,980 --> 00:14:45,200
gente vai fazer isso no próximo vídeo, mas
quando você faz esse comando aqui que eu

213
00:14:45,200 --> 00:14:48,320
estava te mostrando, basicamente é isso
que ele vai fazer, ele vai fazer isso, só

214
00:14:48,320 --> 00:14:52,780
que ele utiliza aqui a função que ela é
chamada de `transcribe`, então se a gente

215
00:14:52,780 --> 00:14:57,320
Olhar no código do próprio Whisper, na lib
aqui, por exemplo, do site-packages, você

216
00:14:57,320 --> 00:15:02,300
vai ver que ele vai chamar isso aqui, essa
função `transcribe` aqui. Então essa função,

217
00:15:02,420 --> 00:15:06,640
opa, essa função aqui `transcribe`, deixa eu
ver se eu acho ela aqui, essa função aqui

218
00:15:06,640 --> 00:15:09,960
`transcribe`, ela é basicamente o que eu tô
pedindo para ele fazer ali quando eu passo

219
00:15:09,960 --> 00:15:13,420
desse jeito, e aí aqui tem várias opções,
que são aquelas opções lá, inclusive tem

220
00:15:13,420 --> 00:15:17,480
mais opções lá do que aqui, porque você
também pode passar as opções de decode

221
00:15:17,480 --> 00:15:22,500
aqui dentro, e aí ele entra aqui, e aí ele
faz todo esse código aqui, tudo isso aqui,

222
00:15:22,580 --> 00:15:27,020
para fazer, ele vai deslizando entre o seu
áudio, então ele pega os primeiros 30

223
00:15:27,020 --> 00:15:31,120
segundos, aí desliza para os próximos 30
segundos e vai fazendo isso até terminar o

224
00:15:31,120 --> 00:15:35,200
seu áudio. Inclusive, dessa forma que a
gente utilizou, ele utiliza os 30 segundos

225
00:15:35,200 --> 00:15:39,960
anteriores para gerar a próxima legenda,
então ele tem um contexto maior. Eu vou te

226
00:15:39,960 --> 00:15:42,480
mostrando isso aqui, mas você está vendo
que o código é enorme, né? E aqui tá

227
00:15:42,480 --> 00:15:45,840
aquele CLI que você viu, que utiliza
`argparse`, que a gente já falou nesse canal,

228
00:15:46,280 --> 00:15:50,060
que é basicamente aqui as opções todas que
você viu ali naquele help, estão aqui,

229
00:15:50,300 --> 00:15:53,260
`argparse` puro ali. Então eu estou te
mostrando aqui só o que acontece por baixo

230
00:15:53,260 --> 00:15:58,780
dos panos. Então, o seu der enter aqui,
ele vai utilizar o model `turbo`. Guarda

231
00:15:58,780 --> 00:16:02,740
essa informação, que eu vou te mostrar ali
depois os models, mas se eu der enter

232
00:16:02,740 --> 00:16:06,100
aqui, o que ele vai fazer? Se for a
primeira vez que você está fazendo isso, o

233
00:16:06,100 --> 00:16:09,940
que ele vai fazer é baixar o model `turbo`
primeiro. Também ele tá falando aqui que o

234
00:16:09,940 --> 00:16:13,920
meu CPU aqui, que eu tô utilizando um Mac,
ele não suporta FP16, que ele tá

235
00:16:13,920 --> 00:16:19,500
utilizando FP32. Isso também é uma opção.
Ele já detectou aqui o português como

236
00:16:19,500 --> 00:16:22,560
áudio que eu tava falando naquela
introdução lá, e aí aqui agora ele vai

237
00:16:22,560 --> 00:16:25,420
começar a fazer a tradução. Vamos
aguardar, vou deixar ele fazer aqui a

238
00:16:25,420 --> 00:16:30,300
tradução e eu vou te mostrar como ficou o
final aqui. Olha só, ele já tá gerando

239
00:16:30,300 --> 00:16:34,540
aqui as legendas e eu já consigo detectar
um probleminha, que ele tá gerando

240
00:16:34,540 --> 00:16:39,340
legendas enormes aqui e isso para mim já
geraria um problema no final das contas,

241
00:16:39,400 --> 00:16:43,460
porque o que aconteceria? Eu teria
legendas que ocupariam muito espaço do

242
00:16:43,460 --> 00:16:46,560
texto. A gente tem como configurar isso
aqui, mas eu quero te mostrar o que ele

243
00:16:46,560 --> 00:16:51,140
gerou. Vê se você lembra se eu falei isso
aqui. Fala aí, pessoal, já ativa a legenda

244
00:16:51,140 --> 00:16:56,040
desse vídeo aí que você vai ver em tempo
real o que eu tô falando. É óbvio, isso é

245
00:16:56,040 --> 00:17:00,660
uma legenda, mas essa legenda ela é
especial, porque ela foi gerada por esse

246
00:17:00,660 --> 00:17:05,020
cara aqui, que é o Whisper da OpenAI, que
é um modelo de inteligência artificial da

247
00:17:05,020 --> 00:17:10,080
OpenAI, que vai basicamente fazer
reconhecimento de fala e através desse

248
00:17:10,080 --> 00:17:14,380
reconhecimento de fala, ele consegue fazer
várias coisas, por exemplo, fazer a

249
00:17:14,380 --> 00:17:18,460
transcrição desse vídeo, que é a legenda
que você tá vendo aí, ou até fazer a

250
00:17:18,460 --> 00:17:22,300
tradução. Eu vou ver depois se eu faço a
tradução dessa transcrição. Olha que

251
00:17:22,300 --> 00:17:25,800
Loucura, eu lembro bem, eu acho que eu
falei precisamente essas palavras. Então

252
00:17:25,800 --> 00:17:30,300
ele está fazendo essa transcrição aqui do
vídeo, até o momento eu não vi nenhum

253
00:17:30,300 --> 00:17:34,400
erro. Eu sei onde ele erra bastante, eu
vou te falar disso aqui. Mas rodando ali o

254
00:17:34,400 --> 00:17:38,560
comando, simplesmente assim, você vai ter
uma legenda assim se ele detectar. Vale

255
00:17:38,560 --> 00:17:42,360
ressaltar uma coisa importante aqui: o meu
áudio está vindo desse microfone, que é

256
00:17:42,360 --> 00:17:48,380
super high-end, ele é muito bom. Eu passo
o meu áudio, vou te mostrar aqui, no OBS, e

257
00:17:48,380 --> 00:17:53,380
tem filtro de ruído aqui. Então esse áudio
está super limpo que você está ouvindo. Pode

258
00:17:53,380 --> 00:17:57,720
ser que se o seu áudio não ficar tão limpo
assim, você precise utilizar alguma das

259
00:17:57,720 --> 00:18:02,040
opções que eu vou te mostrar aqui. Então
vamos lá, a gente viu o Whisper, só o

260
00:18:02,040 --> 00:18:06,460
caminho, e aí ele já gerou as legendas.
Deixa eu te mostrar também onde que essas

261
00:18:06,460 --> 00:18:11,200
legendas foram parar. Então aqui essas
legendas, elas vieram parar na raiz do meu

262
00:18:11,200 --> 00:18:14,240
projeto aqui, porque eu não falei onde eu
queria que ele gerasse a legenda; ele

263
00:18:14,240 --> 00:18:18,460
pegou o mesmo nome do arquivo que eu
mandei para ele, que era oneauto.json, e

264
00:18:18,460 --> 00:18:22,940
aí ele gerou todos os formatos que ele
consegue gerar. Então ele gerou SRT, TSV,

265
00:18:23,100 --> 00:18:27,960
TXT e VTT. Então se você olhar no TXT, é
só o texto que eu falei sem nenhum

266
00:18:27,960 --> 00:18:32,900
timestamp. Se você olhar, por exemplo, o
SRT, ele é o texto que eu falei no

267
00:18:32,900 --> 00:18:37,480
segundo preciso que eu comecei a falar e
terminei de falar. Comecei a falar e

268
00:18:37,480 --> 00:18:41,140
terminei de falar, e assim vai. E aí ele
tem outros formatos ali, como o TSV

269
00:18:41,140 --> 00:18:44,640
também. Eu não conheço esse formato, mas
aparentemente também é de onde eu comecei

270
00:18:44,640 --> 00:18:47,920
e onde eu terminei de falar a frase. Ele
gerou o TXT, que eu já te mostrei, e o

271
00:18:47,920 --> 00:18:52,740
VTT, que parece muito com o SRT, mas
basicamente é um WebVTT aqui, que faz

272
00:18:52,740 --> 00:18:56,800
também essa transcrição. É uma legenda
ali. Como eu não informei, ele gerou todos

273
00:18:56,800 --> 00:19:00,800
esses formatos aqui, mas a gente tem como
informar algumas coisas. Agora a parte

274
00:19:00,800 --> 00:19:04,880
ouro disso aqui, para mim, na minha
concepção, é o JSON, tá? Porque o JSON, o

275
00:19:04,880 --> 00:19:08,480
que ele vai fazer? Eu vou formatar esse
JSON aqui, então aqui no auto-editor, que é Ctrl

276
00:19:08,480 --> 00:19:12,540
Shift I, ele formata esse texto para mim.
Vou dar um Alt Z também para ele quebrar a

277
00:19:12,540 --> 00:19:16,100
linha. E aí ele pega aqui, primeiro, o
texto, e esse é o texto inteiro que você

278
00:19:16,100 --> 00:19:20,840
falou. Esse \u é Unicode, é só um
caractere que representa um acento, ou

279
00:19:20,840 --> 00:19:25,100
algum caractere que não tem na tabela
ASCII. Mas ele gera ali o nosso texto,

280
00:19:25,160 --> 00:19:28,780
bonitinho, e depois ele pega essa parte
aqui, isso eu acho super interessante, que

281
00:19:28,780 --> 00:19:33,760
é os segmentos. Os segmentos, ele vai ter
um ID, que é o ID sequencial, então é tipo

282
00:19:33,760 --> 00:19:37,660
o SRT 0, 1, 2, 3, e assim por diante. Se
eu não me engano, o SRT começa do 1. Mas

283
00:19:37,660 --> 00:19:41,220
ele vai ter um ID, vai ter uma posição,
quando você iniciou e quando você terminou

284
00:19:41,220 --> 00:19:46,780
essa fala aqui, bonitinha; ele tem o texto
desse segmento e ele tem os tokens desse

285
00:19:46,780 --> 00:19:50,480
segmento aqui também. Os tokens são
importantes caso você queira suprimir

286
00:19:50,480 --> 00:19:54,020
algum token; tem essa opção ali também.
Também a temperatura que foi utilizada, eu

287
00:19:54,020 --> 00:19:57,220
Vou falar dessas coisas todas aqui para
você, mas eu só quero te mostrar que você

288
00:19:57,220 --> 00:20:02,320
tem essas opções. E essas opções, como eu
te falei, são o ouro aqui, porque essas

289
00:20:02,320 --> 00:20:07,220
opções te dão a possibilidade de você
saber como o modelo está detectando o seu

290
00:20:07,220 --> 00:20:12,020
áudio. Então a gente viu para onde saíram
essas opções. Voltando aqui, o que mais

291
00:20:12,020 --> 00:20:16,020
que eu tenho aqui? Eu tenho o seguinte, eu
vou olhar pelo meu texto porque está mais

292
00:20:16,020 --> 00:20:21,560
na ordem, eu tenho como escolher o meu
modelo aqui. E aí isso aqui agora vai

293
00:20:21,560 --> 00:20:26,600
envolver parte do seu computador, porque
infelizmente não tem como a gente rodar o

294
00:20:26,600 --> 00:20:31,160
Whisper em qualquer computador. Caso você
não tenha um computador que consiga rodar

295
00:20:31,160 --> 00:20:35,700
o Whisper, você pode utilizar a API da
OpenAI, que ela tem uma API, se eu não me

296
00:20:35,700 --> 00:20:41,600
engano, ela usa o Whisper e também tem
umas versões com GPT-4, alguma coisa

297
00:20:41,600 --> 00:20:45,620
assim. Mas você pode olhar na API que você
pode usar praticamente as mesmas coisas

298
00:20:45,620 --> 00:20:50,340
que eu vou te falar aqui. E aí eu tenho o
modelo, o modelo que ele utiliza por padrão

299
00:20:50,340 --> 00:20:55,680
é o modelo turbo. O modelo turbo é
excelente, super rápido, porém ele requer

300
00:20:55,680 --> 00:21:01,540
6 GB de VRAM para rodar. Então 6 GB de
VRAM não é qualquer computador que vai ter

301
00:21:01,540 --> 00:21:05,420
isso aqui. O que é VRAM? Basicamente,
resumidamente para você, VRAM é a memória

302
00:21:05,420 --> 00:21:09,460
da GPU que você tem. Então basicamente
você precisaria de uma placa de vídeo que

303
00:21:09,460 --> 00:21:13,900
tem pelo menos 6 GB de VRAM para utilizar
esse modelo turbo. Claro, você pode

304
00:21:13,900 --> 00:21:18,200
utilizar modelos menores, que são mais
rápidos, mas que também são menos

305
00:21:18,200 --> 00:21:24,880
precisos. Então eu, como costumo utilizar,
aqui eu tô no Mac M1 Max e esse Mac tem 32

306
00:21:24,880 --> 00:21:29,340
GB de memória. O Mac tem um esquema, dá
uma olhada se o seu computador tem isso

307
00:21:29,340 --> 00:21:33,620
também, que alguns computadores têm isso,
que é um esquema que compartilha a memória

308
00:21:33,620 --> 00:21:38,520
total, que é os 32 GB, ele compartilha
essa memória total com a GPU também, o Mac

309
00:21:38,520 --> 00:21:43,380
aqui. Então o CPU e a GPU utilizam o mesmo
bloco de memória. Então o que eu tiver

310
00:21:43,380 --> 00:21:46,620
disponível ele vai utilizar. Isso me
permite, por exemplo, utilizar os modelos

311
00:21:46,620 --> 00:21:51,240
large sem problema nenhum, que requer mais
ou menos 10 GB de VRAM, mas roda, fica

312
00:21:51,240 --> 00:21:57,140
lento, mas roda. Então você pode utilizar
o modelo tiny, base, small, medium, large e

313
00:21:57,140 --> 00:22:01,720
turbo. Eu tô passando aqui mais por cima,
mas se você vier aqui, eu escrevi muita

314
00:22:01,720 --> 00:22:04,860
informação, muito insight aqui de coisas
que eu fui vendo enquanto eu fui

315
00:22:04,860 --> 00:22:10,200
utilizando o Whisper. Então eu recomendo
super fortemente que você leia isso aqui e

316
00:22:10,200 --> 00:22:13,400
também assista o vídeo, porque eu escrevi
isso aqui, tô gravando o vídeo rapidamente

317
00:22:13,400 --> 00:22:16,820
para você, dá uma ajuda, inclusive curte o
vídeo, já comenta aí, pelo amor de Deus,

318
00:22:17,080 --> 00:22:19,860
vocês não falam nada, vocês não dão
engajamento nesse tipo de vídeo, aí eu

319
00:22:19,860 --> 00:22:24,220
tenho que parar e começar a fazer vídeo
de, sei lá, tomar banho de Nutella na

320
00:22:24,220 --> 00:22:27,560
banheira. Então não dá certo. Então
comenta aí no vídeo, fala assim: oi, ok,

321
00:22:27,820 --> 00:22:32,600
tudo bem, só oi, tudo bem, já tá bom, já é
um comentário. Mas voltando aqui, o tiny

322
00:22:32,600 --> 00:22:38,380
aqui ele requer mais ou menos 1 GB de
VRAM, então isso aqui já é mais fácil de

323
00:22:38,380 --> 00:22:43,660
Você utilizar. Ele não é muito preciso,
mas ele funciona legal. O Base requer

324
00:22:43,660 --> 00:22:47,700
também mais ou menos 1 GB, tá? Então, entre
os dois, talvez usar o Base seria melhor,

325
00:22:47,880 --> 00:22:54,020
porque o Base, todos esses que têm ".en" no
final, eles funcionam tanto só em inglês,

326
00:22:54,240 --> 00:22:58,940
quanto em inglês e outros idiomas. Os
outros aqui que não têm o ".en" no final,

327
00:22:59,060 --> 00:23:02,420
eles são só multidiomas, beleza? É
basicamente essa a diferença. Então, por

328
00:23:02,420 --> 00:23:06,760
isso que alguns têm ".en", que ele funciona
especificamente só em inglês e

329
00:23:06,760 --> 00:23:10,860
multilingual, mas tem uns que não têm isso
aqui. Então tem o Tiny, o Base, o Small, e

330
00:23:10,860 --> 00:23:14,220
aí você vai vendo a quantidade de VRAM que
você precisa aqui. Você pode testar isso

331
00:23:14,220 --> 00:23:17,620
também para ver se roda no seu computador.
Eu costumo utilizar muito aqui, quando eu

332
00:23:17,620 --> 00:23:21,920
tô com tempo, porque isso aqui demora para
caramba, eu costumo utilizar o large-v2,

333
00:23:22,120 --> 00:23:26,960
que para mim foi o melhorzinho dele aqui,
porque eu falo muito termo técnico. Se eu

334
00:23:26,960 --> 00:23:31,440
falar algum termo técnico aqui, por
exemplo, eu vou falar UV sync. Se eu falo

335
00:23:31,440 --> 00:23:34,760
isso, se nessa legenda eu já tiver
corrigido, me perdoe, mas geralmente

336
00:23:34,760 --> 00:23:39,440
quando eu falo isso ele não entende.
Quando eu falo UV add rembg, ele não vai

337
00:23:39,440 --> 00:23:42,360
entender essa frase aqui agora que eu
falei. Então, o que vai acontecer é que eu

338
00:23:42,360 --> 00:23:46,680
vou ter que corrigir essa legenda, e aí
entra o Gemini, que eu passo essa legenda,

339
00:23:47,000 --> 00:23:50,820
falo para ele que isso foi transcrito
pelo... deixa eu te mostrar aqui, para você

340
00:23:50,820 --> 00:23:54,100
entender do que eu estou te falando. Eu passo
isso aqui no Gemini e peço para ele

341
00:23:54,100 --> 00:23:58,640
gerar... tem várias coisas, tem resumo,
tradução, tem SEO, tem várias coisas, mas

342
00:23:58,640 --> 00:24:03,100
vamos pegar isso aqui. Isso aqui eu peço
para o Gemini corrigir a minha legenda. Então

343
00:24:03,100 --> 00:24:06,880
é um código aqui, um script que eu fiz nas
coxas aqui, correndo, mas eu passo chunks

344
00:24:06,880 --> 00:24:10,460
da legenda, trechos da legenda para ele e
falo para ele assim, olha, você é um

345
00:24:10,460 --> 00:24:14,660
revisor técnico de legendas no formato
SRT, SubRip, as legendas foram

346
00:24:14,660 --> 00:24:19,640
transcritas automaticamente por uma IA,
Whisper, e podem conter erros em termos

347
00:24:19,640 --> 00:24:22,880
técnicos de programação. Coloquei um
código aqui para eu passar para ele, esses

348
00:24:22,880 --> 00:24:26,760
termos aqui têm muito erro, aí eu falo rembg,
UV, e assim por diante eu falo para

349
00:24:26,760 --> 00:24:30,900
ele. Seu trabalho é corrigir as palavras
que estejam erradas com base no contexto,

350
00:24:31,040 --> 00:24:35,540
corrigir a pontuação e adicionar letras
maiúsculas no início das frases, manter a

351
00:24:35,540 --> 00:24:39,580
estrutura original da legenda para não
desalinhar o vídeo, respeitar os blocos,

352
00:24:39,580 --> 00:24:43,540
timestamps e quebras de linha e assim por
diante. Eu explico, mostro um exemplo e

353
00:24:43,540 --> 00:24:46,900
ele faz tudo isso e ele fala aqui, por
exemplo, se eu tiver... isso aqui é real,

354
00:24:46,980 --> 00:24:51,400
tá? Se eu tiver uma legenda que foi gerada
sim pelo Whisper, deixa eu abrir o

355
00:24:51,400 --> 00:24:57,360
pyproject.toml, viu o que ele falou ali?
Para configurar o Python, isso já

356
00:24:57,360 --> 00:25:01,760
aconteceu também, eu quero que você me
retorne, deixa eu abrir o pyproject.toml

357
00:25:01,760 --> 00:25:06,420
para configurar o Python. E isso assim,
beleza? E aí eu passo isso aqui dentro do

358
00:25:06,420 --> 00:25:10,880
Gemini, gero essa legenda, gerei essa
legenda, eu finalizo ali, colocando essa

359
00:25:10,880 --> 00:25:14,340
Legenda no YouTube, fazendo resumos,
fazendo artigo de texto e assim por

360
00:25:14,340 --> 00:25:17,600
diante. Então isso é super interessante.
Então eu, conforme eu te falei, costumo

361
00:25:17,600 --> 00:25:21,880
utilizar o model que é o Large, mas aí
isso aí cabe a você olhar no seu sistema

362
00:25:21,880 --> 00:25:26,260
operacional aqui, no caso. Para utilizar o
model, é só você falar "model" e aí o model

363
00:25:26,260 --> 00:25:30,300
que você quer. Por exemplo, suponha que eu
queira utilizar aqui, nesse caso, o model

364
00:25:30,300 --> 00:25:34,320
Tiny. Eu já baixei todos os models aqui,
porque eu testei tudo isso aqui para você,

365
00:25:34,640 --> 00:25:40,400
mas então o model Tiny aqui, ele é bem
rápido para fazer essa tradução, mas ele

366
00:25:40,400 --> 00:25:43,580
não é tão preciso quanto o Turbo. Então
você vê que ele já começou ali, já

367
00:25:43,580 --> 00:25:46,580
detectou o idioma muito mais rápido do
que... eu não sei se eu deixei isso no

368
00:25:46,580 --> 00:25:50,520
vídeo, mas ele é muito mais rápido do que
os outros. E se você passar ele no Tiny e

369
00:25:50,520 --> 00:25:54,400
ver que não está gerando tanto erro, eu
não tô vendo muito erro aqui, se você ver

370
00:25:54,400 --> 00:25:57,820
que não está gerando tanto erro, você pode
utilizar o Tiny mesmo, porque é super mais

371
00:25:57,820 --> 00:26:02,380
rápido e consome muito menos recursos do
seu computador. Agora deixa eu te mostrar

372
00:26:02,380 --> 00:26:06,980
esse mesmo código que eu rodei com o
Large, só para você ver a diferença. Ele

373
00:26:06,980 --> 00:26:12,400
vai levar uma vida para te mostrar o
primeiro ali. Então Large-v2, que é o que

374
00:26:12,400 --> 00:26:16,040
eu gosto de utilizar quando eu tô com
tempo, fica olhando aí e eu vou nesse

375
00:26:16,040 --> 00:26:20,200
momento abrindo aqui o meu sistema, só
para você ver o quanto de recurso ele está

376
00:26:20,200 --> 00:26:23,740
consumindo aqui do meu sistema. Deixa eu
diminuir aqui a telinha para você ver.

377
00:26:23,840 --> 00:26:27,200
Agora que ele está começando, tá
percebendo? Eu tô falando aqui com você

378
00:26:27,200 --> 00:26:33,640
para que eu não corte esse vídeo aqui.
Olha só, ele está consumindo aqui 6 GB

379
00:26:33,640 --> 00:26:37,620
mais ou menos aqui do meu computador, mas
eu já percebi que esses 6 GB que ele está

380
00:26:37,620 --> 00:26:42,280
consumindo do meu computador, ele vai
subindo à medida que o vídeo vai ficando

381
00:26:42,280 --> 00:26:46,560
mais longo. Então ele vai chegar naqueles
10 MB mais ou menos em algum momento do

382
00:26:46,560 --> 00:26:51,560
seu vídeo. Está vendo que ele nem soltou
aqui o primeiro idioma. Então eu nem vou

383
00:26:51,560 --> 00:26:55,220
deixar ele fazer isso, eu só queria que
você visse a quantidade de recurso que

384
00:26:55,220 --> 00:26:59,220
esse model aqui gasta do seu computador.
Dá um Ctrl+C para parar. Se eu voltar para

385
00:26:59,220 --> 00:27:02,740
o Tiny, vamos olhar o quanto que ele gasta
aqui. Voltei para o Tiny, olha só, o

386
00:27:02,740 --> 00:27:08,100
Python aqui está gastando 388 MB e ele já
está fazendo o serviço todo ali. Isso

387
00:27:08,100 --> 00:27:11,080
conforme eu te falei, porque o meu vídeo
tem 3 minutos, se eu não me engano, então

388
00:27:11,080 --> 00:27:15,600
é um vídeo menor, mas ele pode ir subindo
até chegar no 1 GB de memória, depende do

389
00:27:15,600 --> 00:27:19,740
model que você utilizar. Então é isso aqui
sobre model. Deixa eu fechar isso aqui e a

390
00:27:19,740 --> 00:27:23,380
gente pode olhar outras opções aqui.
Voltando aqui, eu tenho o device. Isso

391
00:27:23,380 --> 00:27:28,040
aqui, se você tiver uma placa da Nvidia
com drives CUDA e uma versão compatível

392
00:27:28,040 --> 00:27:33,240
com PyTorch, você pode também utilizar o
device CUDA. No meu caso aqui, eu não

393
00:27:33,240 --> 00:27:36,680
tenho placa de vídeo, porque conforme eu
te falei, eu estou no Mac, então era só eu

394
00:27:36,680 --> 00:27:40,560
utilizar aqui. Eu vou manter sempre o Tiny
aqui por enquanto, mas eu vou colocar o

395
00:27:40,560 --> 00:27:45,080
device aqui e, no meu caso, isso já é
padrão, então não preciso colocar, mas no

396
00:27:45,080 --> 00:27:49,940
meu caso eu coloco device CPU aqui e aí
você colocaria CUDA se você tivesse a

397
00:27:49,940 --> 00:27:56,080
placa da Nvidia. O output_dir é importante
para não sobrecarregar tanto o meu código, que

398
00:27:56,080 --> 00:28:00,020
ele soltou tudo aqui, então eu vou colocar
tudo aqui, vou apagar tudo isso aqui e vou

399
00:28:00,020 --> 00:28:05,960
jogar sempre na pastinha "transcriptions",
por exemplo, então "-o" ou "--output_dir",

400
00:28:05,960 --> 00:28:09,720
deixa eu ver lá, é isso mesmo, "-o" ou
"--output_dir", e o formato também você pode

401
00:28:09,720 --> 00:28:13,380
escolher, que por padrão é "all", já vem
todos que ele sabe fazer aqui. Então eu

402
00:28:13,380 --> 00:28:18,760
vou colocar um "-o", e vou colocar
"transcriptions" aqui, e aí ele já vai criar

403
00:28:18,760 --> 00:28:21,420
a pastinha, se ela não tiver. Deixa eu
cancelar isso aqui também e fazer o

404
00:28:21,420 --> 00:28:24,620
seguinte. Uma outra opção ali, que você vê
sempre que ele dá um warning ali no

405
00:28:24,620 --> 00:28:29,660
começo, falando isso aqui, dois warnings:
primeiro, esse computador aqui, que é o

406
00:28:29,660 --> 00:28:35,520
Mac, não suporta esse FP16, então ele vai
utilizar FP32, que é o float 32,

407
00:28:35,660 --> 00:28:40,280
float 32. O FP16 costuma ser mais rápido,
então por isso que ele tenta primeiro

408
00:28:40,280 --> 00:28:44,180
utilizar o FP16; se não suportar, ele muda
para 32, que é esse caso desse computador

409
00:28:44,180 --> 00:28:47,960
aqui. E também o outro aqui, ele está
falando: "Olha, estou detectando o idioma,

410
00:28:48,080 --> 00:28:52,580
mas se você quiser, use "--language", para
você colocar o idioma certinho que você

411
00:28:52,580 --> 00:28:55,300
quer, que aí eu não te dou esse warning.
Então é basicamente aqui, eu vou falar o

412
00:28:55,300 --> 00:29:02,660
seguinte: --device CPU, transcriptions e
aí --FP16 falso, no meu computador,

413
00:29:02,820 --> 00:29:06,900
nesse caso aqui, só para ele não dar
aquele warning, "--language", aqui eu vou

414
00:29:06,900 --> 00:29:11,900
colocar PT, de PT-BR. "Language" é o idioma
falado no vídeo. Então, se a gente olhar

415
00:29:11,900 --> 00:29:15,860
aqui, o formato eu quero todos ainda.
Então, se você quiser, é só colocar "-f",

416
00:29:15,860 --> 00:29:18,860
qualquer um desses formatos que você quer
usar aqui. E aí aqui eu deixei um exemplo

417
00:29:18,860 --> 00:29:23,260
para você. Uma outra coisa também: ele faz
duas coisas, ele faz isso, e isso que eu

418
00:29:23,260 --> 00:29:28,220
estou falando aqui é o código do Whisper. O
model, ele faz mais do que isso, ele faz

419
00:29:28,220 --> 00:29:31,180
aquelas coisas que estão lá no model, tá?
Então a gente está falando de duas coisas

420
00:29:31,180 --> 00:29:34,720
separadas. Aqui estou falando do código
que a gente está, o comando que a gente está

421
00:29:34,720 --> 00:29:38,220
utilizando. Essa linha de comando, ela
recebe duas opções: ou transcribe ou

422
00:29:38,220 --> 00:29:42,120
translate. As duas fazem a transcrição; a
única diferença é que o transcribe

423
00:29:42,120 --> 00:29:46,540
transcreve para o idioma falado no vídeo,
e o translate ele vai fazer isso, mas ele

424
00:29:46,540 --> 00:29:50,900
só vai gerar o idioma inglês. Então ele
vai ver o que você está falando no vídeo e

425
00:29:50,900 --> 00:29:55,040
vai traduzir isso para inglês. Conforme eu
te falei, você pode utilizar a transcrição

426
00:29:55,040 --> 00:29:59,000
normal do vídeo, que é no idioma falado no
vídeo, para fazer a tradução utilizando

427
00:29:59,000 --> 00:30:03,400
uma API qualquer do Gemini ou do GPT.
Então aqui, ou qualquer outra, estou só

428
00:30:03,400 --> 00:30:07,740
chutando as que eu já utilizei, mas tem
outras. Então aqui a gente pode colocar o

429
00:30:07,740 --> 00:30:12,060
task lá, então --task, isso é padrão já,
estou colocando isso aqui só para você

430
00:30:12,060 --> 00:30:16,380
saber. Então transcribe aqui, ou
translate, esse é o padrão transcribe.

431
00:30:16,740 --> 00:30:19,780
Outra coisa que a gente pode utilizar, que
a gente já viu ali, é o `language`, né?

432
00:30:19,880 --> 00:30:23,780
O `language`, qual que é o idioma falado no
vídeo? Às vezes você está, por exemplo,

433
00:30:24,140 --> 00:30:29,080
esses tempos atrás eu fiz de um anime
aqui, tá? E aí eu precisei utilizar o

434
00:30:29,080 --> 00:30:32,820
idioma falado no vídeo, nem lembro, não
sei se era japonês, coreano, sei lá o que

435
00:30:32,820 --> 00:30:36,300
que é, mas eu tive que utilizar um idioma
desse aqui, mas é difícil saber o que é,

436
00:30:36,300 --> 00:30:40,260
não sei o que são essas letras aqui. Então
você pode pegar a forma longa aqui do

437
00:30:40,260 --> 00:30:43,620
`name`, tá? Então você pode pegar, por
exemplo, aqui ó, tem um nome certinho, em

438
00:30:43,620 --> 00:30:47,380
algum momento você vai ver, português.
Você pode usar as duas formas, tanto com a

439
00:30:47,380 --> 00:30:50,880
forma curta, que é isso aqui, que eu tô
usando lá, ou a forma longa, `language`

440
00:30:50,880 --> 00:30:55,260
português. Ok. Se você quiser ver, você
pode ir lá no código do Whisper, `tokenizer`

441
00:30:55,700 --> 00:31:00,840
`languages`, e aí você vai ver as `languages`
dele, é só você ir lá no `lib` Python, lá

442
00:31:00,840 --> 00:31:04,420
onde você está baixando seus pacotes aí no
seu ambiente virtual, e lá no `tokenizer`

443
00:31:04,420 --> 00:31:08,420
você tem aqui `languages`, que é isso aqui.
E aí você tem lá a forma curta e a forma

444
00:31:08,420 --> 00:31:12,540
longa ali, que é o formato que ele utiliza
ali. Então tem todos aqui, que você pode

445
00:31:12,540 --> 00:31:15,980
olhar aqui também. Beleza, dito isso aqui,
a gente já viu aqui, isso aqui,

446
00:31:16,200 --> 00:31:20,160
`--temperature`, tá? Então vamos olhar essas
partes aqui, que essas partes começam a

447
00:31:20,160 --> 00:31:25,800
entrar em locais assim, mais obscuros,
porque aqui você vai mexer no `model`, você

448
00:31:25,800 --> 00:31:29,900
vai falar como que você quer que ele
trabalhe, tá? Mas vamos fazer isso aqui,

449
00:31:30,300 --> 00:31:34,220
vamos já mandar ele rodar esse comando
aqui, vou aguardar ele terminar, não vou

450
00:31:34,220 --> 00:31:36,980
fazer você aguardar, é óbvio, mas vamos
rodar esse comando, só para ele ficar

451
00:31:36,980 --> 00:31:42,100
salvo ali, e daí a gente já continua lá
falando da parte da temperatura, `--beam_size`,

452
00:31:42,220 --> 00:31:46,340
essas coisas que são interessantes também.
Então pessoal, a temperatura do modelo

453
00:31:46,340 --> 00:31:50,640
aqui. Quando você fala em temperatura, em
qualquer modelo de inteligência artificial

454
00:31:50,640 --> 00:31:53,400
que você vai utilizar, pelo menos a
maioria deles que eu utilizei tem

455
00:31:53,400 --> 00:31:57,820
temperatura, você está falando basicamente
da criatividade daquele modelo, tipo, você

456
00:31:57,820 --> 00:32:03,000
vai dar mais liberdade para ele ser mais
criativo, tentar mais opções, ou você vai

457
00:32:03,000 --> 00:32:07,760
falar para ele ser rigoroso e tentar
somente aquela opção específica. Isso aqui

458
00:32:07,760 --> 00:32:10,820
entra com outras partes aqui, nessas
partes aqui de baixo, que eu vou te

459
00:32:10,820 --> 00:32:15,500
explicar bonitinho. Mas pensa sempre
nisso, criatividade do `model`. Quanto menor

460
00:32:15,500 --> 00:32:19,520
o número, o número aqui no Whisper vai de
0 a 1, e aí você pode colocar `float`

461
00:32:19,520 --> 00:32:25,980
também, então 0, alguma coisa, até 1.
Nesse caso, o Whisper aqui, o 0 é tipo 0

462
00:32:25,980 --> 00:32:30,160
criatividade, essa é a opção que eu
utilizo. Eu tento, por conta de como o meu

463
00:32:30,160 --> 00:32:33,800
áudio é gravado aqui, por exemplo, o
microfone muito limpo, eu não falo muita

464
00:32:33,800 --> 00:32:38,700
gíria, eu falo muito termo técnico, tá?
Mas mesmo com a temperatura 0 ou a

465
00:32:38,700 --> 00:32:43,300
temperatura 1, no meu caso, não muda muita
coisa, ele vai tentar outra palavra, de

466
00:32:43,300 --> 00:32:46,780
outro jeito ali, mas não muda muita coisa.
Então eu sempre deixo a temperatura como

467
00:32:46,780 --> 00:32:51,100
0, mas isso vai depender, conforme eu tô
te falando, da qualidade do seu áudio, da

468
00:32:51,100 --> 00:32:54,440
coisa que a pessoa tá falando dentro
daquele áudio, qual modelo você tá

469
00:32:54,440 --> 00:32:58,440
utilizando, é o Tiny, é o Large, é o
Turbo, então depende de vários fatores

470
00:32:58,440 --> 00:33:02,280
aqui. Isso cabe a você testar e ver o que
vai sair aí para você. Como eu tô te

471
00:33:02,280 --> 00:33:07,460
falando, a maioria das vezes eu utilizo a
temperatura 0. Mas a temperatura 0, ela

472
00:33:07,460 --> 00:33:12,060
ativa algumas opções, e se você começar a
subir a temperatura, começar a dar mais

473
00:33:12,060 --> 00:33:15,740
liberdade para o modelo escolher
determinadas coisas, você pode também

474
00:33:15,740 --> 00:33:19,520
utilizar outras opções. Isso é quase que
como se fosse um IF, eu até criei uma

475
00:33:19,520 --> 00:33:23,040
tabela aqui embaixo para você entender
isso aqui. Mas suponha lá que eu tenho a

476
00:33:23,040 --> 00:33:27,200
temperatura 0, a temperatura 0 é 0
criatividade, mas eu posso ainda

477
00:33:27,200 --> 00:33:32,500
configurar o --beam_size e o --patience, que é
basicamente o --beam_size, vai ser o número

478
00:33:32,500 --> 00:33:37,520
de hipóteses que você mantém em paralelo.
Então o modelo, ele vai fazer o seguinte,

479
00:33:37,600 --> 00:33:41,280
você falou determinada palavra e o modelo
não tem tanta certeza de determinada

480
00:33:41,280 --> 00:33:46,460
palavra, ele vai dar várias possibilidades
para ele escolher ali. E aí, baseado

481
00:33:46,460 --> 00:33:50,640
nessas possibilidades, ele vai escolher a
que tem a maior probabilidade de ser o que

482
00:33:50,640 --> 00:33:54,460
você falou no vídeo. Então isso aqui é
basicamente você dar mais hipóteses para o

483
00:33:54,460 --> 00:33:59,040
modelo, para ele poder selecionar alguma.
E a paciência é a paciência que ele tem

484
00:33:59,040 --> 00:34:04,860
para escolher as palavras ali. Então a
paciência é o fator de tolerância que faz

485
00:34:04,860 --> 00:34:09,200
o modelo continuar explorando novas
hipóteses depois que achar uma aceitável.

486
00:34:09,660 --> 00:34:13,860
Então isso aqui e isso aqui, tanto --beam
size quanto o --patience, é basicamente

487
00:34:13,860 --> 00:34:19,100
usado somente com a temperatura 0. Se a
temperatura for maior do que 0, nesse caso

488
00:34:19,100 --> 00:34:25,700
você precisa utilizar o --best_of aqui no
caso. E outra coisa também é o seguinte, o

489
00:34:25,700 --> 00:34:30,100
--patience aqui, ele basicamente multiplica
o --beam_size. Então se eu tenho, estou

490
00:34:30,100 --> 00:34:35,700
falando assim, de uma leiga para você. O
--beam_size é 2, um exemplo. Se você põe o

491
00:34:35,700 --> 00:34:41,300
--temperature 0, --beam_size 2 e --patience 2,
eu multiplico basicamente o --beam_size.

492
00:34:41,400 --> 00:34:46,160
Então é como se eu estivesse falando para
ele, escolhe o --beam_size 2, duas hipóteses

493
00:34:46,160 --> 00:34:50,720
do que você falou e duas vezes você faz
isso. --patience. Foi basicamente isso que

494
00:34:50,720 --> 00:34:54,440
eu entendi para isso aqui, tá no caso. Mas
uma outra coisa também que você pode fazer

495
00:34:54,440 --> 00:35:00,220
é o modo greedy. O modo greedy é ele achar uma
hipótese só e já usar aquela hipótese, o

496
00:35:00,220 --> 00:35:03,580
que deixa o código um pouco mais rápido.
Um pouco não, bem mais rápido. Porque

497
00:35:03,580 --> 00:35:09,080
quanto mais hipótese você dá para o modelo
e mais paciência, mais lento ele vai ser

498
00:35:09,080 --> 00:35:12,820
para escolher determinada opção. Então se
eu quero, por exemplo, --temperature 0 e

499
00:35:12,820 --> 00:35:18,180
--beam_size 1, isso aqui, a paciência aqui
não funciona. O --patience não vai

500
00:35:18,180 --> 00:35:23,420
funcionar. Se eu colocar --temperature 0 e o
--beam_size maior do que 1, aí sim entra em

501
00:35:23,420 --> 00:35:27,200
ação a paciência. Entendeu a lógica? Então
é basicamente isso aqui. Isso com

502
00:35:27,200 --> 00:35:30,860
--temperature 0. Se eu tiver --temperature
maior do que 0, ou seja, mais

503
00:35:30,860 --> 00:35:35,160
criatividade, aí ele funciona de um
formato diferente. Aqui com --beam_size ele

504
00:35:35,160 --> 00:35:40,380
utiliza hipóteses. Na --best_of, ele vai
escolher amostras. Ele vai pegar várias

505
00:35:40,380 --> 00:35:44,200
amostras diferentes do que ele tiver e aí
ele vai escolher entre as determinadas

506
00:35:44,200 --> 00:35:47,920
amostras ali. Você pode testar as duas
opções. Conforme eu te falei, eu testei

507
00:35:47,920 --> 00:35:52,520
tudo isso aqui antes de falar isso aqui
para você e no meu caso eu não vi muita

508
00:35:52,520 --> 00:35:56,720
diferença. Andei pesquisando tudo sobre
isso aqui e o que acontece é que isso vai

509
00:35:56,720 --> 00:36:00,640
entrar em ação quando você tiver um áudio
muito ruim ou quando a pessoa está falando

510
00:36:00,640 --> 00:36:04,800
muita gíria ou muito termo técnico naquele
determinado vídeo, aí isso aqui vai entrar

511
00:36:04,800 --> 00:36:09,180
em ação. E aí uma cola rápida aqui para
você é o seguinte: quando a temperatura

512
00:36:09,180 --> 00:36:13,840
for maior do que 0, ele vai utilizar
amostras, sampling. Então aí aqui nesse

513
00:36:13,840 --> 00:36:18,480
caso só funciona a opção --best_of e aí o
padrão são 5 amostras que ele utiliza.

514
00:36:18,600 --> 00:36:22,560
Quando você põe a temperatura maior do que
0, ele já faz automaticamente isso, mas se

515
00:36:22,560 --> 00:36:25,780
você quiser mudar por mais ou menos
amostras, você pode utilizar essa opção.

516
00:36:26,160 --> 00:36:30,740
Quando a temperatura for igual a 0, ele
utiliza Beam Search e aí nesse caso, que

517
00:36:30,740 --> 00:36:36,660
são as hipóteses lá, ele vai por padrão
utilizar 5 Beam Search, 5 hipóteses e o

518
00:36:36,660 --> 00:36:42,740
--patience por padrão é 1. Então esses vão
ser somente 5 hipóteses. Se eu aumento

519
00:36:42,740 --> 00:36:45,980
aqui o --patience, como eu te falei antes,
eu vou basicamente multiplicar o meu

520
00:36:45,980 --> 00:36:50,180
número de hipóteses. Novamente, isso foi o
que eu entendi disso aqui. O que ele faz?

521
00:36:50,440 --> 00:36:54,080
Porque eu também fiquei olhando o código,
como o código estava escrito lá, então eu

522
00:36:54,080 --> 00:36:58,480
fui bem a fundo nisso aqui. E aí aqui
nesse caso essa parte é ignorada, o Best

523
00:36:58,480 --> 00:37:03,580
Of é ignorado. Sempre que a temperatura
for 0, o --best_of é ignorado. O temperatura

524
00:37:03,580 --> 00:37:09,520
igual a 0 e o --beam_size igual a 1, isso é
chamado de greedy. Ele vai basicamente achar

525
00:37:09,520 --> 00:37:13,340
a primeira hipótese e já usar, não vai
ficar pensando muito ali, costuma ser mais

526
00:37:13,340 --> 00:37:18,640
rápido aqui. O padrão é temperatura 0 e o
--beam_size igual a 5, beleza? Esse é o

527
00:37:18,640 --> 00:37:22,640
padrão. Se a gente mudar ali, a gente pode
até ver se ele vai ser mais rápido. Então

528
00:37:22,640 --> 00:37:29,740
se eu coloco, por exemplo, a temperatura 0
e o --beam_size igual a 1, que vai ser o

529
00:37:29,740 --> 00:37:34,500
greedy, o Tiny em teoria vai ficar bem mais
rápido aqui do que do jeito que eu estava

530
00:37:34,500 --> 00:37:37,200
utilizando antes. Você vê que ele já está
cuspindo a legenda praticamente inteira,

531
00:37:37,260 --> 00:37:41,220
já vai chegar no final em, sei lá, 10
segundos. Isso porque eu utilizei o Tiny

532
00:37:41,220 --> 00:37:45,820
ali, mas também corre maior chance dele
errar. Uma dica aqui de bolso para você:

533
00:37:46,200 --> 00:37:50,880
Quando você utiliza as opções padrão, do
jeito que o Whisper vem, já funciona, para

534
00:37:50,880 --> 00:37:54,900
mim pelo menos, já funciona perfeitamente.
Você não precisa mudar muita coisa em como

535
00:37:54,900 --> 00:37:58,800
o modelo trabalha. Aqui eu explico aqui
tudo para você, até falo na prática, o

536
00:37:58,800 --> 00:38:02,800
modelo vai responder da forma que ele foi
treinado, independente do seu capricho nas

537
00:38:02,800 --> 00:38:08,040
configs. Então, trocar a temperatura, beam
size, --patience e afins, talvez, dependendo

538
00:38:08,040 --> 00:38:12,080
do seu áudio, pode virar desperdício de
tempo. Quando que eu mexeria nisso aqui,

539
00:38:12,160 --> 00:38:15,860
se eu fosse mexer? Muitas vezes, isso
depende do áudio também, isso já aconteceu

540
00:38:15,860 --> 00:38:19,700
em algumas vezes comigo, o modelo pode
entrar em loop. Tipo, ele pega uma

541
00:38:19,700 --> 00:38:23,680
palavra, a última palavra que ele detectou
ali, tipo "1", ele fala "1", aí ele fica

542
00:38:23,680 --> 00:38:27,100
falando "1", "1", "1", até acabar aqueles 30
segundos. Então, ele entra em loop ali.

543
00:38:27,500 --> 00:38:31,840
Nesse caso, aí sim eu começo a mexer no
--beam_size, no --patience, nessas coisas, e

544
00:38:31,840 --> 00:38:35,940
tem outras opções ali embaixo que também
podem mudar como o modelo funciona

545
00:38:35,940 --> 00:38:40,200
ali. Uma outra coisa que tem já, por
padrão também, é --temperature Increment on

546
00:38:40,200 --> 00:38:44,740
Fallback. Caso ele descarte determinada
opção, ele vai tentar de novo,

547
00:38:45,060 --> 00:38:48,880
basicamente, com essa opção aqui. Por
padrão, essa opção sobe um pouco a

548
00:38:48,880 --> 00:38:53,320
temperatura para 0.2, e aí, de qualquer
jeito, ele vai tentar gerar algum texto

549
00:38:53,320 --> 00:38:56,500
ali para você. Se ele conseguir detectar
qualquer coisa, ele vai gerar algum texto

550
00:38:56,500 --> 00:39:00,440
ali para você, ou se ele não conseguir, ele
vai entrar em loop, aí você começa a

551
00:39:00,440 --> 00:39:04,320
utilizar as opções. Isso aqui é super
interessante, que é o seguinte: Max Line

552
00:39:04,320 --> 00:39:09,700
Width é, basicamente, a largura da linha
ali. Então, isso aqui, você está

553
00:39:09,700 --> 00:39:14,140
percebendo que aqui, ele está gerando
legendas enormes. Isso não acontece

554
00:39:14,140 --> 00:39:18,660
sempre, é bom testar isso aqui, porque o
que acontece? Às vezes, ele gera legendas

555
00:39:18,660 --> 00:39:23,120
no tamanho perfeito para você. Só que se
você deixar o modelo gerar as legendas, o

556
00:39:23,120 --> 00:39:27,100
que pode acontecer é exatamente isso aqui.
Porque, para mim, essas legendas que ele

557
00:39:27,100 --> 00:39:30,240
está gerando aqui, deixa eu ver quantos
caracteres tem nessa linha aqui, ele está

558
00:39:30,240 --> 00:39:36,580
gerando 102 caracteres numa linha só, fica
difícil de ler. Então, eu costumo gerar a

559
00:39:36,580 --> 00:39:41,060
legenda com 42 de largura, mais ou menos,
ou você pode escolher também as palavras.

560
00:39:41,380 --> 00:39:45,480
Mas vamos olhar aqui as opções. Por
padrão, lá no código hardcoded está 1000 o

561
00:39:45,480 --> 00:39:49,000
tamanho, por isso que ele permite que o
modelo gere isso aqui. Está lá no Subtitles

562
00:39:49,000 --> 00:39:54,500
Writer, na classe deles lá. Mas aqui, eu
falei 42 para você, coloquei 45 aqui, eu

563
00:39:54,500 --> 00:39:58,780
uso 42, eu fiz. Depois, se eu lembrar, eu
corrijo isso aqui. Mas isso aqui vai

564
00:39:58,780 --> 00:40:03,480
corrigir, só que isso precisa que você
ative o --words_timestamp. Porque o que

565
00:40:03,480 --> 00:40:09,180
acontece? Aí ele vai começar a marcar por
palavra. Então, ele começa a marcar o

566
00:40:09,180 --> 00:40:13,720
timestamp de onde você falou a e
finalizou. Nesse caso, ele marca por

567
00:40:13,720 --> 00:40:17,240
palavra especificamente. Então, cada
palavra tem o seu começo, fim, começo,

568
00:40:17,420 --> 00:40:21,500
fim, começo e fim. Isso permite que você
faça quase que um karaokê ali. Porque o

569
00:40:21,500 --> 00:40:24,720
que vai acontecer? Você pode ativar uma
opção que é --highlight_words, eu não sei se

570
00:40:24,720 --> 00:40:28,460
eu pus essa opção aqui, mas ele coloca um
sublinhado em tudo que você está falando,

571
00:40:28,560 --> 00:40:31,820
no momento exato que você está falando. Só
que isso aqui demora um pouquinho mais.

572
00:40:32,040 --> 00:40:35,180
Mas vamos testar, o que a gente tem que
fazer? Primeira coisa, eu preciso colocar


573
00:40:35,180 --> 00:40:40,240
`words_timestamps` como `True`. Vamos colocar
aqui no comando. Vou colocar `words_`

574
00:40:40,240 --> 00:40:45,240
`timestamps` como `True`. Vou colocar essa
opção `--max_line_width`, beleza. E aí eu já

575
00:40:45,240 --> 00:40:49,400
vou colocar uma outra opção aqui para te
explicar. Esse `--max_line_width` eu coloco

576
00:40:49,400 --> 00:40:55,360
42, conforme eu te falei, e o `--max_line_count` eu quero que ele gere no máximo duas

577
00:40:55,360 --> 00:41:00,600
linhas. Esse `max` aí é que é confuso,
porque ao meu ver não é máximo, é `line_`

578
00:41:00,600 --> 00:41:04,940
`count` mesmo. Por que que acontece? Ao
ativar essa opção, o que vai acontecer é

579
00:41:04,940 --> 00:41:09,440
que agora sempre as minhas legendas vão
ter duas linhas. E isso não vem do `model`

580
00:41:09,440 --> 00:41:13,400
aqui, você vai ver que, se eu não me
engano, ele no gerar, aqui na hora que ele

581
00:41:13,400 --> 00:41:18,160
gera, não é aqui que isso funciona. Isso é
na legenda final. Então aqui ele continua

582
00:41:18,160 --> 00:41:21,780
gerando do mesmo jeito, mas na legenda
final, olha aí como é que ficou. Ele gera

583
00:41:21,780 --> 00:41:26,960
até 42 caracteres, deu 41 nessa linha e
duas linhas. Mas percebe uma coisa, por

584
00:41:26,960 --> 00:41:31,700
que que eu estava falando que o `max` pode
induzir a gente ao erro? O `max` não é `max`,

585
00:41:31,840 --> 00:41:35,500
ele é duas linhas, literalmente. Porque
olha, todas as legendas agora têm duas

586
00:41:35,500 --> 00:41:40,180
linhas. Duas linhas, duas linhas e assim
vai assim por diante. Então é isso que

587
00:41:40,180 --> 00:41:44,740
isso aqui faz. Ao invés também de você
utilizar `line_width` aqui, você pode

588
00:41:44,740 --> 00:41:49,820
utilizar também a quantidade de `words` por
linha, `--max_words_per_line`. Essa opção

589
00:41:49,820 --> 00:41:54,100
aqui, ela permite que você fale quantas
palavras você quer por linha, mas essa

590
00:41:54,100 --> 00:42:00,940
opção, se você utilizar `--max_line_width`,
isso aqui é anulado. Ou você usa `--max_words_per_line`

591
00:42:00,940 --> 00:42:05,980
ou `--max_line_width`. Eu não uso
essa opção, eu uso essas duas aqui de cima

592
00:42:05,980 --> 00:42:09,460
que eu te falei. E aí esse `--highlight_words`
é super interessante, porque o que que

593
00:42:09,460 --> 00:42:12,980
acontece? Deixa que eu te mostrar, isso
aqui é super legal. Todas essas opções que

594
00:42:12,980 --> 00:42:16,480
eu tô te falando precisam do `words_timestamps`
e isso aqui costuma deixar o

595
00:42:16,480 --> 00:42:19,720
comando um pouquinho mais lento. Um
pouquinho não, às vezes dependendo do

596
00:42:19,720 --> 00:42:24,900
módulo ele deixa o seu comando bem mais
lento. Eu vou gerar isso aqui e eu vou te

597
00:42:24,900 --> 00:42:29,040
mostrar isso aqui, esse `--highlight_words`
`True`, no caso. Eu não sei se eu pus essa

598
00:42:29,040 --> 00:42:33,300
opção aqui. `--highlight_words` é isso aqui.
Esse `--highlight_words` que eu coloquei aqui,

599
00:42:33,380 --> 00:42:36,680
eu não coloquei o valor, depois se eu
lembrar eu altero. O valor aqui é para

600
00:42:36,680 --> 00:42:39,760
você ativar, então você tem que colocar o
`True` aqui na frente, conforme eu coloquei

601
00:42:39,760 --> 00:42:43,600
aqui. Então deixa eu executar isso aqui
para a gente ver o que que ele vai falar.

602
00:42:44,000 --> 00:42:47,700
Então ele tá gerando a legenda normal e eu
quero te mostrar que ele vai me falar isso

603
00:42:47,700 --> 00:42:51,700
aqui no tempo que eu tô falando as
palavras aqui. Então olha que legal, deixa

604
00:42:51,700 --> 00:42:56,220
eu ver se eu consigo ativar isso aqui para
você ver. Eu vou pegar lá o nosso vídeo, o

605
00:42:56,220 --> 00:43:00,280
vídeo aqui, deixa eu preparar tudo aqui e
eu já te mostro. Tô colocando o vídeo

606
00:43:00,280 --> 00:43:04,860
aqui, o vídeo que eu tô rodando, vou nas
legendas, vou adicionar uma legenda e vou

607
00:43:04,860 --> 00:43:09,780
lá onde eu tô gravando a transcrição
e vou colocar isso aqui,

608
00:43:09,900 --> 00:43:12,740
essa legenda que a gente gerou. Então
percebe aqui comigo, deixa eu tentar


609
00:43:12,740 --> 00:43:15,480
Deixar isso aqui melhor para você
entender. Deixa eu colocar um fundo.

610
00:43:15,740 --> 00:43:19,220
Percebe comigo que ele está colocando um
underline em cada palavra que eu estou

611
00:43:19,220 --> 00:43:23,040
falando, precisamente na hora que eu falo
a palavra. Olha só, isso é super legal.

612
00:43:23,120 --> 00:43:27,840
Deixa eu só ouvir aqui para ver se está
dando certo. Perfeito, está batendo

613
00:43:27,840 --> 00:43:32,120
perfeitamente aqui a palavra com aonde ele
está sublinhando, então faz quase que um

614
00:43:32,120 --> 00:43:36,280
efeito de karaokê, só que fica um pouco
mais lento, infelizmente. Então beleza,

615
00:43:36,420 --> 00:43:40,800
geramos aqui essa legenda com essas opções
todas aqui. Então aqui eu coloquei um

616
00:43:40,800 --> 00:43:44,260
comando completo para você ver, eu
coloquei essa barra invertida aqui só para

617
00:43:44,260 --> 00:43:48,000
o comando ficar quebrando linha, mas
geralmente você escreve isso tudo para

618
00:43:48,000 --> 00:43:52,440
frente, ou no Unix ou Linux e Mac eu
escrevo assim o comando mesmo, mas essas

619
00:43:52,440 --> 00:43:55,860
barras é só demonstrando que eu quebrei a
linha aqui para te mostrar esse comando

620
00:43:55,860 --> 00:44:00,580
completo. Ah, uma outra coisa interessante
aqui que a gente tem aqui no Whisper é o

621
00:44:00,580 --> 00:44:04,920
`--initial_prompt`, que é o seguinte, tá? Isso
aqui me deu um trabalhão, porque eu testei

622
00:44:04,920 --> 00:44:09,680
de várias formas possíveis aqui e acabei
não vendo muita utilidade, eu não vi muita

623
00:44:09,680 --> 00:44:14,480
função nisso aqui. Por quê? O que
acontece? Isso serve, sinceramente, para

624
00:44:14,480 --> 00:44:19,140
você, na minha concepção isso serve para
confundir o módulo, porque o que é essa

625
00:44:19,140 --> 00:44:24,200
opção? É o primeiro contexto dos primeiros
30 segundos do vídeo. Então o que ele faz?

626
00:44:24,400 --> 00:44:28,920
O Whisper converte os primeiros 30
segundos e a partir do segundo ele pega o

627
00:44:28,920 --> 00:44:33,220
contexto do anterior, no caso. Então os
primeiros 30 segundos ele fica meio que

628
00:44:33,220 --> 00:44:37,500
sem contexto. Se você quiser utilizar esse
`--initial_prompt`, você pode dar um toque

629
00:44:37,500 --> 00:44:40,780
para ele, falar olha, nisso aí eu falei
determinada coisa. Eu já tentei usar isso

630
00:44:40,780 --> 00:44:45,220
aqui de todas as formas que você puder
imaginar, falando quais palavras que eu estou

631
00:44:45,220 --> 00:44:49,740
falando ao longo do vídeo todo, falando
sobre o que o vídeo é, tem algumas

632
00:44:49,740 --> 00:44:55,560
discussões aqui no repositório da OpenAI
que fala sobre isso aqui. Testei com

633
00:44:55,560 --> 00:44:58,720
algumas opções aqui, não vi muito
funcionamento interessante nisso aqui,

634
00:44:58,780 --> 00:45:03,320
pelo menos na linha de comando. Depois no
código talvez mude o funcionamento disso

635
00:45:03,320 --> 00:45:07,780
aqui. Mas como eu estou te falando, isso
funciona nos primeiros 30 segundos muito

636
00:45:07,780 --> 00:45:11,740
bem. Se nos primeiros 30 segundos você
falar alguma palavra que ele detectou

637
00:45:11,740 --> 00:45:15,220
errado, você pode passar esse `--initial_prompt`
e falar o que você está falando. Como

638
00:45:15,220 --> 00:45:19,820
o caso que eu testei aqui, eu estava falando
do REMBG, que é para remover o fundo de

639
00:45:19,820 --> 00:45:23,640
imagens. Nesse caso eu peguei um
trechinho, cortei um trechinho do vídeo e

640
00:45:23,640 --> 00:45:28,040
falei onde eu falava esse REMBG. E aí
nesse caso se eu falar no `--initial_prompt`

641
00:45:28,040 --> 00:45:31,840
para ele que eu falei a palavra REMBG,
porque ele pega essa palavra errado, se eu

642
00:45:31,840 --> 00:45:36,600
falar isso para ele, ele entende e corrige
nos primeiros 30 segundos. Se no segundo,

643
00:45:37,000 --> 00:45:41,920
segundo os 30 segundos ali, no próximo
bloco, eu não falar a palavra REMBG,

644
00:45:41,980 --> 00:45:46,680
porque daqui no primeiro eu falei REMBG,
ele acertou. No segundo, se eu falo REMBG,


645
00:45:46,800 --> 00:45:50,460
Ele vai pegar o contexto dos 30 segundos
anteriores e não esse --initial_prompt.

646
00:45:50,900 --> 00:45:54,480
Então o que vai acontecer é que, como eu
falei duas vezes nos dois blocos a mesma

647
00:45:54,480 --> 00:45:59,140
palavra, ele acerta de novo. Se no
terceiro bloco eu não falei REMBG e aí no

648
00:45:59,140 --> 00:46:02,820
quarto eu falo, ele perdeu esse contexto,
aí ele vai começar a errar de novo. Então

649
00:46:02,820 --> 00:46:06,420
achei assim, isso aqui pode ser muito útil
para caso você queira dar o nome, alguém

650
00:46:06,420 --> 00:46:10,720
falou o seu nome no começo da frase, ele
pegou errado, alguma coisa assim, só nos

651
00:46:10,720 --> 00:46:14,340
primeiros 30 segundos. E aí depende da
repetição, no caso, conforme eu estava te

652
00:46:14,340 --> 00:46:17,260
explicando. Então, --initial_prompt eu não
vou nem usar, mas basicamente você daria

653
00:46:17,260 --> 00:46:20,040
um toque ali para ele. Eu até deixei uma
analogia aqui para você entender melhor.

654
00:46:20,540 --> 00:46:25,000
Imagine que é como você está atrás de um
palco e você vai dar uma dica para um

655
00:46:25,000 --> 00:46:28,780
cantor. Aí o cantor está vindo subir no
palco, você fala: "Olha aí, tem 300 mil

656
00:46:28,780 --> 00:46:33,000
pessoas ali te aguardando". O cantor já vai
subir no palco, vai ver aquelas 300 mil

657
00:46:33,000 --> 00:46:36,480
pessoas, 30 segundos iniciais e aí é o
show, e aí esquece, ele já esqueceu

658
00:46:36,480 --> 00:46:41,600
daquilo. Então ele vai continuar fazendo o
show dele, mas o seu contexto que você deu

659
00:46:41,600 --> 00:46:45,360
foi só para ele dar o primeiro passo no
palco, o resto é com ele. Então, isso por

660
00:46:45,360 --> 00:46:51,640
isso que você utiliza isso aqui. Isso aqui
também pode causar algum problema,

661
00:46:51,760 --> 00:46:55,300
conforme eu te falei. Dependendo de como
você escreve esse --initial_prompt, você

662
00:46:55,300 --> 00:46:59,780
pode fazer o modelo começar a gerar umas
legendas enormes, você pode fazer o modelo

663
00:46:59,780 --> 00:47:03,720
entrar em looping de repetição. Então, por
isso que eu falei na sinceridade que isso

664
00:47:03,720 --> 00:47:07,740
aqui é meio que para confundir o modelo e
quem vai utilizar o modelo, porque se você

665
00:47:07,740 --> 00:47:15,680
usar isso errado vai ficar estranho a sua
transcrição. Dito isso, você também pode

666
00:47:15,680 --> 00:47:19,760
fazer o seguinte: se você quiser testar o
--initial_prompt, você pode cortar o vídeo

667
00:47:19,760 --> 00:47:24,140
com o FFmpeg. Então o FFmpeg, como você
teve que instalar ele para usar o Whisper,

668
00:47:24,460 --> 00:47:30,220
o FFmpeg recebe um comando assim: `ffmpeg` e
`"-i"`, a entrada, e aí para ser mais rápido

669
00:47:30,220 --> 00:47:36,920
você copia o codec de vídeo, `-c:v`,
`copy`, copia o codec de áudio `-c:a`,

670
00:47:36,920 --> 00:47:41,240
`copy`, e aí você pode falar onde você
quer que comece aquele vídeo, o corte

671
00:47:41,240 --> 00:47:44,980
dele, nesse caso aqui são cinco minutos,
então ele vai começar esse vídeo dos cinco

672
00:47:44,980 --> 00:47:49,120
minutos, e onde eu quero que termine, `-to`
no caso aqui, que vai terminar em 10

673
00:47:49,120 --> 00:47:53,020
minutos. O que eu vou fazer? Imagine que o
meu vídeo tem 30 minutos, eu vou pegar do,

674
00:47:53,140 --> 00:47:57,560
vou gerar um novo vídeo que começa dos
cinco minutos desse vídeo, que vai até os

675
00:47:57,560 --> 00:48:01,800
10 minutos, ou seja, eu vou gerar um corte
nesse vídeo de cinco minutos com o FFmpeg.

676
00:48:02,140 --> 00:48:05,480
E daí eu tenho um vídeo novo. Essa é uma
forma de você testar. Uma outra forma de

677
00:48:05,480 --> 00:48:10,240
você testar é utilizando a opção `clip`
`timestamps` do próprio Whisper, onde você

678
00:48:10,240 --> 00:48:14,200
passa aqui o segundo inicial e o segundo
final, onde você quer que ele comece a

679
00:48:14,200 --> 00:48:18,040
transcrição. E aí nesse caso ele vai
deixar, ele vai só pegar o vídeo naquele

680
00:48:18,040 --> 00:48:21,620
local que você falou, e aí ele vai fazer a
transcrição. Eu explico melhor mais para

681
00:48:21,620 --> 00:48:26,400
Baixo esse --clip_timestamps. Aqui eu
expliquei já o comando do FFmpeg. Aqui

682
00:48:26,400 --> 00:48:29,880
também é o seguinte, isso aqui é o que eu
tava te falando, isso vem por padrão, mas

683
00:48:29,880 --> 00:48:36,280
você pode desativar. Quando o modelo usa os
30 segundos iniciais, a partir daqui ele

684
00:48:36,280 --> 00:48:40,600
vai sempre, por padrão, utilizar o
contexto dos 30 segundos anteriores, no

685
00:48:40,600 --> 00:48:44,040
próximo contexto. Então, do segundo para
frente ele sempre tem os 30 segundos

686
00:48:44,040 --> 00:48:48,400
anteriores como contexto. Isso faz com que
o modelo basicamente tenha um minuto de

687
00:48:48,400 --> 00:48:52,500
contexto do vídeo, que ele não se perca,
ele saiba o que você tava falando antes,

688
00:48:52,680 --> 00:48:56,080
para ele não começar sempre do zero.
Porque a gente sabe que quanto mais

689
00:48:56,080 --> 00:49:00,440
contexto a gente tiver, melhor. Então, ele
faz isso por padrão, pegar o contexto do

690
00:49:00,440 --> 00:49:05,580
bloco anterior. Mas caso você veja que
isso tá gerando loop de erro, aquele

691
00:49:05,580 --> 00:49:09,620
problema, tá gerando algum erro que tá
fazendo ele carregar esse erro para outros

692
00:49:09,620 --> 00:49:14,520
blocos, você pode testar, desativar. É só
você colocar `condition_on_previous_text`

693
00:49:14,520 --> 00:49:19,840
como falso. E daí, nesse caso, ele vai estar
condicionado a não usar nenhum contexto,

694
00:49:19,920 --> 00:49:24,280
ele vai usar só os 30 segundos de áudio, o
que pode também deixar o seu texto menos

695
00:49:24,280 --> 00:49:28,040
consistente, né? No caso, porque ele não
vai lembrar o que ele falou nos 30

696
00:49:28,040 --> 00:49:32,060
segundos anteriores, mas tem essa opção
aqui. Ok, deixei algumas recomendações

697
00:49:32,060 --> 00:49:35,860
aqui para você e aqui alguns parâmetros
que eu não usei ou quase não usei, mas que

698
00:49:35,860 --> 00:49:40,620
são interessantes para você ver. Não
testei `length_penalty` aqui. Ele controla a

699
00:49:40,620 --> 00:49:46,520
penalização de sequências longas, valor
típico entre 0.6 e 1. Eu não testei, só

700
00:49:46,520 --> 00:49:50,620
pesquisei o que isso faz, então eu não vou
nem entrar em detalhes sobre isso aqui.

701
00:49:50,940 --> 00:49:55,320
Esse aqui é interessante, isso aqui eu já
usei algumas vezes. Isso aqui, `suppress_`

702
00:49:55,320 --> 00:50:02,480
tokens, ele permite que você corte algumas
coisas que podem ser lixo para dentro do

703
00:50:02,480 --> 00:50:05,660
modelo. Às vezes você vai falar, isso ele
já faz por padrão, ele já vem com `-1` que

704
00:50:05,660 --> 00:50:09,860
vai cortar a maioria das coisas. Ah,
hum, essas coisinhas que a gente fala,

705
00:50:10,180 --> 00:50:14,000
barulhos que talvez ele detecte como um
barulho ou fala, ele já corta essas coisas

706
00:50:14,000 --> 00:50:19,300
automaticamente com `-1`. Mas se você
quiser ser específico, você pode pegar os

707
00:50:19,300 --> 00:50:23,560
tokens aqui e passar para esse `suppress_`
tokens aqui. Aqui um exemplo para você.

708
00:50:23,780 --> 00:50:28,800
Isso aqui vai cortar algumas coisas úteis.
Só como exemplo para você, se o seu texto

709
00:50:28,800 --> 00:50:34,140
for "Olá pessoal, este é o meu texto, com
uma vírgula". Imagina assim, "Olá pessoal,

710
00:50:34,480 --> 00:50:39,900
vírgula, este é o meu texto, ponto". Se eu
passar esses tokens aqui, que são esses

711
00:50:39,900 --> 00:50:44,220
que eu coloquei aqui embaixo, dessa frase
inteira, o seu texto não vai ter nenhuma

712
00:50:44,220 --> 00:50:47,740
dessas coisas. Então, seu texto vai ficar
sem vírgula, vai ficar sem "Olá", sem

713
00:50:47,740 --> 00:50:51,160
"pessoal" e sem ponto. Olha aqui, eu vou
pegar isso aqui e vou te mostrar esse

714
00:50:51,160 --> 00:50:55,580
funcionamento. Eu vou vir aqui, tá vendo
que tem várias vírgulas aqui e deve ter

715
00:50:55,580 --> 00:50:58,960
ponto em algum lugar. Deixa eu ver se eu
acho algum ponto aqui. Aparentemente, ele

716
00:50:58,960 --> 00:51:07,920
não gerou nenhum ponto aqui, mas as
vírgulas. Com aqueles `suppress_tokens`, eu

717
00:51:07,920 --> 00:51:11,840
Estou suprimindo uma vírgula também ali,
que eu copiei de lá. Então, se eu executar

718
00:51:11,840 --> 00:51:15,260
esse comando, ele não vai pôr nenhuma
vírgula aqui no texto. Então, vou executar

719
00:51:15,260 --> 00:51:19,840
só para você ver. Olha só, ele não está
pondo nenhuma vírgula e já mudou o

720
00:51:19,840 --> 00:51:24,560
comportamento. Você tá vendo que já mudou
a forma como ele gera a largura da legenda

721
00:51:24,560 --> 00:51:28,760
por algum motivo. Tem que ir testando para
você ver o que vai acontecer. Cada coisa

722
00:51:28,760 --> 00:51:33,160
que eu faço aqui muda a forma como ele
funciona. Agora ele está gerando legendas

723
00:51:33,160 --> 00:51:37,780
que são usáveis, são bem mais curtas, mas
eu já estava passando a opção de `--max_line_count`

724
00:51:37,780 --> 00:51:42,660
lá. E aqui está o sublinhado que eu
mostrei para você antes, mas eu já estava

725
00:51:42,660 --> 00:51:47,840
passando o `--max_line_count`, aquelas opções,
então ele aqui mudou. Mas fica estranho,

726
00:51:47,940 --> 00:51:52,380
tá vendo que aqui tinha que ter um ponto
ou uma vírgula para vir daqui para cá e

727
00:51:52,380 --> 00:51:56,240
assim por diante. Então, cabe testar essas
informações aqui. São super interessantes,

728
00:51:56,400 --> 00:52:01,140
mas como eu te falei, testa elas primeiro.
Caso você queira saber quais são os tokens

729
00:52:01,140 --> 00:52:05,860
aqui, aqui eu só entrei no Python, só para
te mostrar. Eu entrei no Python normal

730
00:52:05,860 --> 00:52:10,060
aqui e aí se eu der um `print(1, 2, 3)`,
você já deve ter visto isso, óbvio, né?

731
00:52:10,240 --> 00:52:13,960
Mas eu tô só no Python normal, então o que
eu posso fazer? Eu já tô neste projeto

732
00:52:13,960 --> 00:52:17,760
aqui com o ambiente virtual ativo. Então,
se eu importar o `from whisper.tokenizer`

733
00:52:17,760 --> 00:52:24,440
`import get_tokenizer`, ele vai importar. Ok,
importado. Se eu falar `tokenizer =`

734
00:52:24,440 --> 00:52:29,120
`get_tokenizer(True)`, o primeiro
ali é `multilingual`, é `multilingual`, eu

735
00:52:29,120 --> 00:52:36,160
quero. O número de idiomas que o Whisper
suporta, 99 aqui no caso, acho que são 99,

736
00:52:36,300 --> 00:52:42,640
eu sei. O idioma português que eu vou
utilizar e o `task` que é `transcribe`, eu

737
00:52:42,640 --> 00:52:46,480
posso utilizar esse `tokenizer`. Então agora
eu posso falar, por exemplo, aqui na opção

738
00:52:46,480 --> 00:52:49,720
lá, eu tava pegando lá, pessoal, vírgula,
esse é meu texto. Se você quiser converter

739
00:52:49,720 --> 00:52:55,880
um texto em tokens, você usa o `encode`, por
exemplo, `token.encode` e aí você pode falar

740
00:52:55,880 --> 00:53:00,860
lá, "Olá mundo", esses são os tokens que o
modelo pega ali, ó. Nesse caso aqui, `token`

741
00:53:00,860 --> 00:53:04,760
`.encode`, o que eu coloquei? `tokenizer`,
gente, eu coloquei `token`. `tokenizer`

742
00:53:04,760 --> 00:53:09,680
`.encode`, ele tá mostrando quais foram os
tokens que eu peguei. Ah, eu quero saber o

743
00:53:09,680 --> 00:53:15,580
que é o 401. `tokenizer.decode` e aí
eu passo uma lista com quais tokens eu

744
00:53:15,580 --> 00:53:21,140
quero. Eu quero só o 401, é o que? É um
"Olá", no caso, tá vendo? "Olá". E o próximo ali

745
00:53:21,140 --> 00:53:31,200
é 842, vai ser "A", um "A" normal. O outro ali
é o 7968, que é "mundo". Então, se eu passar

746
00:53:31,200 --> 00:53:34,900
todos esses tokens aqui, deve gerar, deve
gerar não, né? Vai gerar o que eu te

747
00:53:34,900 --> 00:53:39,100
falei, que é o texto lá. Então aqui, ó,
"Olá mundo", foi a palavra que esse

748
00:53:39,100 --> 00:53:42,740
`tokenizer` gerou. Então isso aqui é
interessante para você saber qual token e

749
00:53:42,740 --> 00:53:45,860
também, além disso aqui, tá? Isso aqui que
eu tô falando é para você saber qual

750
00:53:45,860 --> 00:53:48,620
token, caso você queira, olha, eu quero
ver qual token que ele tá gerando aqui.

751
00:53:48,780 --> 00:53:52,320
Mas uma outra coisa que você pode fazer
também é o seguinte, vem lá no JSON que

752
00:53:52,320 --> 00:53:56,820
Ele gera e aí você pode olhar. Eu acho
mais difícil assim e mais impreciso, mas

753
00:53:56,820 --> 00:54:01,380
você pode fazer assim, ó. Se eu pegar aqui
o texto qualquer que ele falou ali, eu

754
00:54:01,380 --> 00:54:04,920
posso olhar quais tokens que ele gerou
aqui, ó. Então aqui deve bater aqui, ó.

755
00:54:05,120 --> 00:54:07,820
Isso aqui deve ser um espaço, né? Esse
inicial aqui. Vamos olhar aqui, ó, esse

756
00:54:07,820 --> 00:54:13,600
aqui, 50364. Eu acho que é um espaço
aquilo lá. Vamos lá. É, realmente é um

757
00:54:13,600 --> 00:54:16,940
texto vazio, tá vendo? Mas só para você
entender isso aqui que eu tava te falando,

758
00:54:17,240 --> 00:54:20,780
você pode ir olhando aqui no que ele
gerou, tá? E não bate certinho, que você

759
00:54:20,780 --> 00:54:25,460
vê que a palavra "olá", ele pegou "OL" e "A"
separado, não bate aqui certinho. Então eu

760
00:54:25,460 --> 00:54:28,880
acho uma forma que eu te mostrei mais
precisa, para eu saber o que que é cada

761
00:54:28,880 --> 00:54:34,180
coisa. Por exemplo, se eu pego isso aqui,
ó, essa lista aqui, ó, e colo lá, a gente

762
00:54:34,180 --> 00:54:38,760
consegue ver, fazer o decode dessa lista
aqui. Então, colando, no caso aqui, vai

763
00:54:38,760 --> 00:54:43,440
ficar errado por conta do seguinte. Deixa
eu corrigir aqui, ó, para não ter nenhuma

764
00:54:44,600 --> 00:54:48,060
indentação. E aí a gente olha isso lá.
Então olhando aqui agora, tá vendo? Ficou

765
00:54:48,060 --> 00:54:53,600
super estranho. Colei, agora vai. Então,
olha lá, "olá", aí a gente vai ver o que eu

766
00:54:53,600 --> 00:54:58,240
estou falando, beleza? Então é basicamente
isso aqui. E aí, parece que o modelo Tiny

767
00:54:58,240 --> 00:55:02,980
tá super impreciso aqui, tá? Então eu
gosto de utilizar modelos maiores, mas eu

768
00:55:02,980 --> 00:55:07,020
tô usando Tiny aqui só para te mostrar de
forma mais rápida o que que ele tá

769
00:55:07,020 --> 00:55:14,060
gerando. Então vamos olhar outras opções.
Esse FP16 é float16 ou float32. Float16

770
00:55:14,060 --> 00:55:18,600
costuma ser mais rápido, né? É mais
rápido. Então, aqui para ele não me gerar

771
00:55:18,600 --> 00:55:21,480
um warning, eu acho que eu já coloquei,
não já? Deixa eu ver. É, eu coloquei, ó.

772
00:55:21,640 --> 00:55:26,000
Para ele não me gerar um warning, eu
coloquei FP16 falso. Mas não faz isso não,

773
00:55:26,060 --> 00:55:30,400
se ele não gerar warning, ele tá usando
FP16 no seu ali. E isso aqui é uma das

774
00:55:30,400 --> 00:55:35,240
primeiras linhas de código lá do
`transcribe`. Se você olhar no `transcribe`,

775
00:55:35,980 --> 00:55:40,900
que é essa função deles aqui, é uma das
primeiras linhas lá que eu estava te

776
00:55:40,900 --> 00:55:45,660
mostrando antes. Ele vai checar o quê
aqui? Deixa eu ver aqui em cima. Aqui, lá

777
00:55:45,660 --> 00:55:49,800
no comecinho ele vai checar se o seu
`device`, no caso aqui, se você estiver

778
00:55:49,800 --> 00:55:54,940
falando que você quer FP16 como `tool`, ou
no caso se você não estiver falando, ele

779
00:55:54,940 --> 00:56:00,240
vai tentar o 32. Mas eu acho que é isso
aqui. Ele vai ver se o modelo `device` for

780
00:56:00,240 --> 00:56:06,120
CPU, aí ele não vai utilizar o FP32. É, é
isso mesmo aqui. Aí ele checa se o

781
00:56:06,120 --> 00:56:10,140
dispositivo tem CUDA aqui no caso, se
entrar aqui dentro aqui, porque se você

782
00:56:10,140 --> 00:56:14,940
estiver utilizando CPU e assim por diante.
Eu tô lendo o código aqui, mais ou menos,

783
00:56:15,040 --> 00:56:18,800
para você aqui, mas é das primeiras linhas
aqui, onde ele te fala, olha, se o seu

784
00:56:18,800 --> 00:56:26,420
dispositivo não suportar o FP16, ele vai
utilizar FP32. Para as próximas opções,

785
00:56:26,560 --> 00:56:32,040
vamos olhar aqui. Isso aqui é interessante
também, que é o seguinte, `Compression`

786
00:56:32,040 --> 00:56:37,060
`Ratio Threshold`. Isso aqui, ele faz o
seguinte, ele vai, imagine que você tem

787
00:56:37,060 --> 00:56:42,140
aqui uma palavra, uma frase desse tipo
aqui, e fica repetindo aqui a mesma coisa.

788
00:56:42,540 --> 00:56:47,180
Quando você compacta isso aqui com Gzip,
que é o que ele utiliza aqui, o que vai

789
00:56:47,180 --> 00:56:50,940
acontecer é que a razão de compressão fica
muito alta, porque se repetir um monte de

790
00:56:50,940 --> 00:56:54,000
coisa, a compressão é inteligente o
suficiente para jogar essas coisas tudo

791
00:56:54,000 --> 00:56:58,660
numa coisa só. E aí a compressão fica
alta, você comprimiu muito aquele trecho.

792
00:56:58,860 --> 00:57:03,740
Quando você fala uma coisa bem mais
diversa, com várias palavras separadas,

793
00:57:03,800 --> 00:57:08,200
que é o jeito que a gente costuma falar
mesmo, a compressão é menor. Então o que

794
00:57:08,200 --> 00:57:12,480
acontece? Ele consegue detectar, se em
determinado trecho, o Whisper entrou em

795
00:57:12,480 --> 00:57:17,820
loop, ficando repetindo determinada coisa
ali. Se isso acontecer com você, você pode

796
00:57:17,820 --> 00:57:22,500
testar o Compression Ratio como zero, e aí
testar para ver se isso aqui melhora ou

797
00:57:22,500 --> 00:57:27,640
não. O valor padrão é 2.4. Eu não lembro
se isso tem lá naquele JSON, deixa eu ver

798
00:57:27,640 --> 00:57:33,660
aqui. Aquele JSON gerado para gente aqui,
ele tem. Olha só, aqui o meu Compression

799
00:57:33,660 --> 00:57:37,980
Ratio, daquele trecho ali que eu estava
olhando, que é esse trechinho aqui, esse

800
00:57:37,980 --> 00:57:42,660
aqui de cima, esse Compression Ratio foi
um ponto, isso é valor todo aqui. Por isso

801
00:57:42,660 --> 00:57:45,780
que eu estava te falando que esse JSON é
super importante para gente, porque ele

802
00:57:45,780 --> 00:57:50,280
mostra como o model está funcionando.
Então nesse caso aqui, ele está dentro do

803
00:57:50,280 --> 00:57:55,500
padrão. Se passasse lá de 2.4, a gente
teria um problema. Isso não é uma coisa

804
00:57:55,500 --> 00:57:59,340
que eu mexo muito se eu não tiver nenhum
problema, eu mantenho sempre o padrão. Mas

805
00:57:59,340 --> 00:58:03,640
conforme eu estou te falando, a razão de
compressão é exatamente aquilo lá que você

806
00:58:03,640 --> 00:58:07,620
vê no JSON. Você pode olhar caso o seu
model entre em loop, ou ele está gerando

807
00:58:07,620 --> 00:58:11,080
algum negócio muito atrapalhado, você pode
conferir também a razão de compressão lá

808
00:58:11,080 --> 00:58:15,960
no JSON e ver se ela está passando do
padrão que é 2.4. Eu acho que nenhum dos

809
00:58:15,960 --> 00:58:22,440
meus aqui passa de 2.4. Deixa eu até
buscar aqui, e ir olhando. Todos estão 1.7

810
00:58:22,440 --> 00:58:28,740
alguma coisa, todos eles. Aqui subiu um
pouquinho, 1.89. Fica nessa faixa. Nenhum

811
00:58:28,740 --> 00:58:32,520
passou de 2.0 aqui, a razão de compressão.
Porque a gente costuma falar palavras

812
00:58:32,520 --> 00:58:36,300
muito diversas aqui, então geralmente a
gente não vai ter problema com isso. Mas

813
00:58:36,300 --> 00:58:42,400
aqui ficou bem alto, ficou 1.9. Foi mais
alto que eu vi até agora, mas caso você

814
00:58:42,400 --> 00:58:46,040
tenha problema, você pode testar essa
opção aqui também. Vamos olhar aqui para

815
00:58:46,040 --> 00:58:52,960
baixo, esse log probe threshold também tem
lá o AVG, se você ver, é isso aqui, AVG

816
00:58:52,960 --> 00:58:57,500
log probe. E aí ele te dá um valor aqui
desse log probe. Deixa eu voltar ali para

817
00:58:57,500 --> 00:59:02,420
a gente ver. Isso aqui é a média do
logaritmo de probabilidade. Complexas as

818
00:59:02,420 --> 00:59:08,380
coisas, né? Se a média do logaritmo de
probabilidade, log probe, dos tokens

819
00:59:08,380 --> 00:59:13,440
estiver abaixo do valor, aqui no caso, ele
trata como um erro. Eu errei. Aí ele vai

820
00:59:13,440 --> 00:59:17,440
para o fallback lá, usa uma temperatura
mais alta. Mas o padrão é menos 1. Então

821
00:59:17,440 --> 00:59:22,840
você consegue ver o AVG log probe, a média
do logaritmo de probabilidade das frases

822
00:59:22,840 --> 00:59:28,420
transcritas pelo Whisper usando aquele JSON
lá que eu te mostrei no final. Já te falei

823
00:59:28,420 --> 00:59:32,600
desse JSON, né? Está vendo aqui? Isso aqui
é a média, o valor padrão é menos 1. Então

824
00:59:32,600 --> 00:59:39,980
Se ele ficar abaixo desse valor aqui, ele
vai considerar aquilo como um erro e aí

825
00:59:39,980 --> 00:59:44,000
ele vai tentar de novo com uma temperatura
mais alta, que é aquele fallback de

826
00:59:44,000 --> 00:59:48,700
temperatura lá. Novamente, eu vou repetir
isso para você, porque essas opções eu só

827
00:59:48,700 --> 00:59:53,860
vim utilizar para fazer esse vídeo, para
falar sobre o Whisper. Não é uma coisa que eu

828
00:59:53,860 --> 00:59:57,740
fico utilizando o tempo inteiro. Eu falei
isso já algumas vezes. Então se eu tiver

829
00:59:57,740 --> 01:00:05,760
errado, eu pesquisei, perguntei para a IA,
eu li o paper que tem aqui da OpenAI, esse

830
01:00:05,760 --> 01:00:10,120
paper aqui, você pode ler também, é mais
assim, fala como o model foi treinado, mas

831
01:00:10,120 --> 01:00:14,340
eu li esse paper deles aqui todo para te
explicar essas coisas. Então não é um

832
01:00:14,340 --> 01:00:18,980
negócio que eu tô tirando da minha cabeça,
mas também não é um negócio que eu tô 100%

833
01:00:18,980 --> 01:00:24,220
certo do que está acontecendo. Eu acho que
nem eles lá do model estão 100% certos de

834
01:00:24,220 --> 01:00:28,920
como o model funciona, porque várias vezes
você vê os pesquisadores falando e parece

835
01:00:28,920 --> 01:00:33,140
que eles estão falando de que o model se
comportou desse jeito, como se o model

836
01:00:33,140 --> 01:00:36,660
tivesse vida própria no caso. Mas você
pode testar essas opções, dá uma lida

837
01:00:36,660 --> 01:00:41,500
aqui, porque isso aqui foi a base de muita
pesquisa e como eu te falei, lê o paper,

838
01:00:41,620 --> 01:00:45,640
lê as coisas todas. Isso aqui é o no
speech threshold, eu não me lembro de ter

839
01:00:45,640 --> 01:00:48,960
usado isso aqui, mas isso é uma coisa que
me interessa, que é o seguinte, o modelo

840
01:00:48,960 --> 01:00:52,860
consegue saber parte de silêncio. Se o
modelo acredita que é silêncio, ele vai

841
01:00:52,860 --> 01:00:59,480
utilizar esse token aqui, no speech,
falando e a decodificação falha. Ele

842
01:00:59,480 --> 01:01:03,460
descarta esse trecho como sendo silêncio,
isso ajuda a cortar os respiros, essas

843
01:01:03,460 --> 01:01:07,900
coisas, ou até algum barulho estranho ali,
que apareça, barulho não vai ser silêncio,

844
01:01:08,000 --> 01:01:11,980
então descarta isso que eu falei. Mas isso
aqui ele vai tratar como silêncio e isso é

845
01:01:11,980 --> 01:01:16,040
uma parte que me interessa dele, que é
aquele VAD lá, que eu tava olhando para

846
01:01:16,040 --> 01:01:20,580
talvez tentar fazer alguma coisa que corte
os silêncios dos vídeos utilizando a IA,

847
01:01:20,700 --> 01:01:23,640
mas isso é uma coisa mais para frente,
fala aí se você quer que eu falo disso

848
01:01:23,640 --> 01:01:28,520
aqui mais para frente. Essa parte aqui,
mas me deu uma dor de cabeça, mas nossa

849
01:01:28,520 --> 01:01:31,980
senhora, isso aqui eu testei demais,
porque o que acontece? Vou te explicar o

850
01:01:31,980 --> 01:01:37,540
meu problema aqui. Eu trabalhei somente, a
maioria, 90% do tempo eu trabalhei com o

851
01:01:37,540 --> 01:01:41,800
meu idioma em português, em alguns
momentos eu peguei alguma coisa em

852
01:01:41,800 --> 01:01:46,240
japonês, coreano, inglês, se eu não me
engano. Peguei alguns idiomas, mas isso

853
01:01:46,240 --> 01:01:51,980
foi um caso a parte específico só. Só que
o que acontece? Nenhum dos idiomas que eu

854
01:01:51,980 --> 01:01:57,200
testei tem alguma pontuação que vem atrás
das palavras, porque existe idioma que a

855
01:01:57,200 --> 01:02:02,880
pontuação começa no começo da palavra.
Esse prepend punctuation, seria ao meu

856
01:02:02,880 --> 01:02:07,140
entender o seguinte, este argumento
controla quais caracteres de pontuação

857
01:02:07,140 --> 01:02:12,600
aparecem antes de uma palavra e devem ser
colados à palavra seguinte, em vez de

858
01:02:12,600 --> 01:02:17,220
serem tratados como um token separado. O
que isso significa? Aqui, se eu pegasse

859
01:02:17,220 --> 01:02:21,660
algum segmento qualquer aqui, você percebe
aqui o que ele faz? Olha só, se a gente

860
01:02:21,660 --> 01:02:25,680
Observar, ele faz o seguinte: no texto é
isso aqui, esse texto é esse segmento,

861
01:02:25,700 --> 01:02:30,480
beleza? Imagine que tem uma pontuação aqui
no comecinho, sei lá, acho que no espanhol

862
01:02:30,480 --> 01:02:36,300
deve ter como “está”, no caso. Lá nessa
pontuação do começo, ele tem duas opções,

863
01:02:36,680 --> 01:02:42,940
o modelo pode tanto separar essa pontuação
em uma palavra separada aqui, ou ele pode

864
01:02:42,940 --> 01:02:46,820
unir essa pontuação com a palavra
posterior, que seria basicamente, imagine

865
01:02:46,820 --> 01:02:51,460
que tem a pontuação atrás, imagine aqui,
ele pode tratar o ponto de interrogação invertido

866
01:02:51,460 --> 01:02:55,860
como um ponto solto, ou ele pode colar
nessa palavra, é isso que aquilo faz.

867
01:02:56,180 --> 01:03:00,240
Então, quando você fala essa opção aqui,
você fala basicamente, isso é o padrão,

868
01:03:00,420 --> 01:03:05,000
então ele fala incluir aspas, parênteses,
vírgulas, requer `words_timestamps=true` também,

869
01:03:05,220 --> 01:03:09,280
que é aquela, fazer timestamps por
palavra. E aí eu falei, em teoria, se o

870
01:03:09,280 --> 01:03:13,400
modelo gerasse, por exemplo, esse trecho,
isso aqui eu acho que é real, eu acho que

871
01:03:13,400 --> 01:03:17,780
essa palavra “argumento”, ela é dividida em
três pedaços, mas se ele gerasse “argument”,

872
01:03:18,340 --> 01:03:22,160
aqui, separadamente, tipo assim, esses
tokens aqui, vamos olhar esses dois tokens

873
01:03:22,160 --> 01:03:25,740
só para a gente confirmar, eu não sei se
eu deixei isso aberto, eu acho que eu não

874
01:03:25,740 --> 01:03:29,500
deixei isso aberto, não, nem dá, mas é,
isso aqui seria a representação disso

875
01:03:29,500 --> 01:03:34,400
aqui, no caso. Percebe que tem uma
pontuação que está aqui, essa pontuação,

876
01:03:34,440 --> 01:03:39,860
ela está separada desse “arg” aqui, se eu
fizer isso aqui e não colocar essa

877
01:03:39,860 --> 01:03:43,640
pontuação aqui, o que ele vai fazer é
tratar tanto isso aqui, quanto isso aqui

878
01:03:43,640 --> 01:03:49,420
separados, se eu usar o padrão dessa forma
aqui, ele vai unir isso aqui com essa

879
01:03:49,420 --> 01:03:53,060
palavra aqui. Aí eu deixei uma observação
importante para você: eu testei o Whisper

880
01:03:53,060 --> 01:03:57,440
majoritariamente com dois idiomas,
português e inglês, até testei um ou

881
01:03:57,440 --> 01:04:02,900
outro, mas foi bem pouco, e o que acontece
aqui, no meu caso de uso, é que eu não

882
01:04:02,900 --> 01:04:08,360
consegui ver nenhum local onde ele gerasse
uma pontuação anterior, eu até cheguei a

883
01:04:08,360 --> 01:04:13,380
olhar as funções lá do código do Whisper,
que são as funções que fazem isso aqui,

884
01:04:13,460 --> 01:04:17,560
que é lá no `timing`, se eu não me engano,
que está aqui, deixa eu ver se é isso aqui

885
01:04:17,560 --> 01:04:23,000
mesmo, é isso aqui mesmo, é essa função
aqui, que está lá no `timing`, que é essa

886
01:04:23,000 --> 01:04:27,580
`merge_punctuations` aqui, que ela recebe
essas coisas, ela recebe uma lista de

887
01:04:27,580 --> 01:04:32,000
palavras, ali basicamente, tem tokens
palavras aqui, mas ela recebe uma lista

888
01:04:32,000 --> 01:04:36,800
com as palavras separadas, e aí ela recebe
o que você vai fazer o `prepend`, lá daquela

889
01:04:36,800 --> 01:04:40,940
opção, e o `append`, que eu não falei ainda,
mas tem depois, essa eu consegui ver. E aí

890
01:04:40,940 --> 01:04:45,320
o que ela faz é entrar aqui dentro, ver se
a palavra tem, isso eu achei estranho, ela

891
01:04:45,320 --> 01:04:50,360
checa se a palavra anterior começa com um
espaço, e eu percebi que os pontos no

892
01:04:50,360 --> 01:04:53,920
Whisper não tem espaço, então achei
estranho isso aqui, mas tudo bem. Então

893
01:04:53,920 --> 01:04:58,300
ele checa se a palavra anterior começa com
um espaço, e se a palavra anterior sem o

894
01:04:58,300 --> 01:05:02,800
espaço, que é o ponto sem espaço, está no
que você está passando aqui, e aí ele faz

895
01:05:02,800 --> 01:05:07,380
toda a jogada aqui para unir ou separar
essa pontuação. Isso é para `prepend`,


896
01:05:07,440 --> 01:05:11,560
Prepend eu não consegui ver, mas o append,
que é o depois, isso sim eu consegui ver,

897
01:05:12,100 --> 01:05:16,700
e aí o append, deixa eu voltar aqui, o
append, que é essa parte aqui, é a mesma

898
01:05:16,700 --> 01:05:20,680
coisa, esse argumento ele controla quais
caracteres de pontuação aparecem depois de

899
01:05:20,680 --> 01:05:24,840
uma palavra, que devem ser coladas às
palavras anteriores. Isso é a mesma coisa,

900
01:05:24,940 --> 01:05:28,920
mas é o inverso. Novamente, isso eu
consegui ver, isso dá para fazer. Então, se

901
01:05:28,920 --> 01:05:33,420
você coloca isso aqui, o que ele vai fazer
é colar essa pontuação que você colocou

902
01:05:33,420 --> 01:05:38,220
aqui na palavra. Então, por exemplo, se
você tem dois tokens gerando "ok", e aí tem

903
01:05:38,220 --> 01:05:43,560
um ponto solto, quando você passa isso
aqui, separadamente, a interrogação vai

904
01:05:43,560 --> 01:05:48,620
ficar colada na palavra no final, gerando
"ok?". E aí deixei uma dica

905
01:05:48,620 --> 01:05:52,680
aqui, esses argumentos de pontuação só
farão alguma diferença perceptível se

906
01:05:52,680 --> 01:05:58,480
você, por algum motivo, estiver utilizando
o timestamp da palavra especificamente

907
01:05:58,480 --> 01:06:02,820
para você ver se o ponto está colado ou
não com determinada palavra. Para mim, não

908
01:06:02,820 --> 01:06:06,320
fez a mínima diferença isso aqui, porque
eu não utilizo esses recursos, mas

909
01:06:06,320 --> 01:06:10,320
conforme eu tô te falando, eu testei cada
uma dessas opções, uma ou outra que eu não

910
01:06:10,320 --> 01:06:14,620
consegui testar aqui. Beleza, outras
coisas úteis, threads. O threads é a

911
01:06:14,620 --> 01:06:18,640
quantidade de threads que você vai
utilizar do seu computador. Eu testei com

912
01:06:18,640 --> 01:06:23,720
1, 4, 10, 100 e 1000. O que aconteceu foi
que basicamente o meu CPU foi só

913
01:06:23,720 --> 01:06:28,120
consumindo mais recursos, mas não mudou
nada a velocidade de transcrição aqui.

914
01:06:28,360 --> 01:06:33,520
Isso pode fazer alguma diferença em outras
máquinas, na minha não fez. Mas deixa com

915
01:06:33,520 --> 01:06:37,560
padrão, padrão é 0, 0 ele vai usar o
quanto ele precisar ali e beleza. Isso

916
01:06:37,560 --> 01:06:41,320
aqui é interessante, --clip_timestamps,
muito mais utilizado na minha concepção

917
01:06:41,320 --> 01:06:46,580
para... é, eu acabei de pensar aqui no
uso, mas vamos supor que você quer pegar

918
01:06:46,580 --> 01:06:50,640
um trecho do vídeo, ou vários trechos,
pode ser tudo de uma vez. Você pode

919
01:06:50,640 --> 01:06:55,480
utilizar isso aqui com segundos, com start
e end. Então, por exemplo, nesse caso, se

920
01:06:55,480 --> 01:06:59,840
eu falar 10 e 30, o que ele vai fazer é
transcrever somente dos 10 segundos até os

921
01:06:59,840 --> 01:07:04,820
30 segundos daquele vídeo. Nada mais do
que isso. Mas, além disso também, você

922
01:07:04,820 --> 01:07:08,500
pode passar várias vezes isso aqui. Então,
eu pensei numa coisa assim útil para isso

923
01:07:08,500 --> 01:07:12,080
aqui. Primeiro, para teste, eu quero
testar determinado trechinho do vídeo, não

924
01:07:12,080 --> 01:07:16,480
quero transcrever o vídeo inteiro, beleza.
Eu posso também querer transcrever, como

925
01:07:16,480 --> 01:07:20,420
eu estava te falando antes, trechos de
vídeos em idiomas diferentes. Isso pode

926
01:07:20,420 --> 01:07:24,020
ser interessante. Às vezes, do segundo
zero até o 30, a pessoa está falando

927
01:07:24,020 --> 01:07:28,120
francês, aí eu transcrevo todas as partes
que ela falou francês. Depois também eu

928
01:07:28,120 --> 01:07:31,320
faço outra transcrição, todas as partes
onde ela falou português, ou qualquer

929
01:07:31,320 --> 01:07:34,560
outro idioma. Então, esse foi um caso de
uso que eu pensei agora, nesse momento.

930
01:07:35,640 --> 01:07:39,740
Você pode passar também várias coisas.
Então, é sempre assim, início, fim, start,

931
01:07:39,880 --> 01:07:45,880
end. Isso aqui funciona perfeitamente, mas
se você fizer alguma coisa assim, nesse

932
01:07:45,880 --> 01:07:51,160
Caso aqui, eu passei, começa só o start,
né? Então, ele começa dessa parte e vai

933
01:07:51,160 --> 01:07:54,000
até o fim. Isso aqui pode ser que
funcione, beleza. Para mim, funcionou

934
01:07:54,000 --> 01:07:58,600
tranquilo. Ele começou dos 4 minutos e 30
segundos e foi até o final do vídeo. Mas

935
01:07:58,600 --> 01:08:02,820
eu testei de uma forma que eu acho que não
estava previsto isso. Ele começando dos

936
01:08:02,820 --> 01:08:07,320
60, indo até 120, e depois só pus um zero,
para ver o que ele ia fazer. Ele faz

937
01:08:07,320 --> 01:08:12,820
exatamente o que está escrito aqui. Começa
dos 60 a transcrever, vai até os dois, ou

938
01:08:12,820 --> 01:08:17,300
um minuto até dois minutos, ok, e
continua. Mas ele continua o seguinte, ele

939
01:08:17,300 --> 01:08:20,820
volta no começo do vídeo e traduz até o
final. Então, parece que isso não foi

940
01:08:20,820 --> 01:08:25,120
pensado. Se você vê aqui, eu até escrevi.
Atenção, esse último caso parece não ter

941
01:08:25,120 --> 01:08:30,000
sido previsto. Aqui ele vai, o zero que
vem depois dos 120, lá, faz o módulo

942
01:08:30,000 --> 01:08:36,140
voltar no começo da transcrição e começar
de novo. Isso fez o meu VLC aqui até rodar

943
01:08:36,140 --> 01:08:40,920
essa legenda, mas ele cortou o trecho
inicial do vídeo, por algum motivo. Mesmo

944
01:08:40,920 --> 01:08:47,060
ele tendo voltado no começo e transcrito
de novo, eu acho que o VLC reordenou as

945
01:08:47,060 --> 01:08:51,360
legendas ali, e aí o que aconteceu foi que
ele cortou o trecho inicial, mesmo ele

946
01:08:51,360 --> 01:08:56,660
tendo feito isso aqui. Ele fez essa
transcrição, mas o VLC cortou. Então, isso

947
01:08:56,660 --> 01:09:00,120
é um caso aqui que eu não usaria, tá?
Então, eu só usaria isso assim, início,

948
01:09:00,360 --> 01:09:05,940
fim, início, fim, talvez um início,
posterior ao anterior sempre, mas talvez

949
01:09:05,940 --> 01:09:10,360
um início e não por fim, ele vai até o
final. Isso aqui também é interessante.

950
01:09:10,360 --> 01:09:16,040
Inclusive, lá no FFmpeg, você pode fazer
com o -ss e o -to, esses dois comandos,

951
01:09:16,100 --> 01:09:21,580
você pode usar só um ou outro também, que
o -ss e o -to, se você passar só o -to, ele

952
01:09:21,580 --> 01:09:25,980
vai só até aquele trecho, do início até
aquele trecho. Se você passar só o -ss,

953
01:09:26,680 --> 01:09:31,720
ele vai daquele -ss até o final do vídeo.
Então, beleza. E essa outra parte aqui, eu

954
01:09:31,720 --> 01:09:36,960
não testei, não cheguei nem a tocar nesse
argumento, mas é a `hallucination silence`

955
01:09:36,960 --> 01:09:41,440
`threshold`, funciona junto com o `word
timestamps` e tenta detectar trechos de

956
01:09:41,440 --> 01:09:47,360
silêncio longo, que o model pode ter
alucinado, inventado algum texto. Se você

957
01:09:47,360 --> 01:09:52,680
passar um 1.5, ele vai ignorar silêncios
maiores que 1.5, que gera um texto

958
01:09:52,680 --> 01:09:56,400
suspeito. Novamente, não toquei nesse
argumento, você pode testar aí para você

959
01:09:56,400 --> 01:09:59,820
ver. Então, eu chego no fim aqui das
coisas. Eu acho que a gente passou por

960
01:09:59,820 --> 01:10:03,960
todas as opções do Whisper aqui, tá? Eu
acho que você não vai achar nenhum vídeo

961
01:10:03,960 --> 01:10:08,160
tão profundo assim sobre o Whisper e nesse
ponto a gente só tá falando da linha de

962
01:10:08,160 --> 01:10:12,440
comando do Whisper. A gente ainda vai ter
um próximo vídeo sobre o Whisper falando

963
01:10:12,440 --> 01:10:16,020
de código, ou seja, a gente vai fazer
alguma coisa qualquer para a gente embutir

964
01:10:16,020 --> 01:10:19,900
o Whisper dentro do nosso código e, sei
lá, fazer uma transcrição, alguma coisa

965
01:10:19,900 --> 01:10:23,280
assim. Mas, ao invés de eu fazer isso
nesse vídeo, que eu acho que vai dar mais

966
01:10:23,280 --> 01:10:27,060
de uma hora, a gente faz isso no próximo
vídeo juntos, beleza? Então é isso,

967
01:10:27,200 --> 01:10:28,500
pessoal. Te vejo no próximo vídeo.
